from __future__ import annotations
import argparse
import json
import warnings
warnings.filterwarnings('ignore')
import os
from pathlib import Path
from dataclasses import dataclass
from typing import Tuple, Optional, Dict, List, Any, Union
from collections import deque
import random
from datetime import datetime
from scenario_charts_3 import create_scenario_visualizations
import numpy as np
import pandas as pd
import matplotlib
matplotlib.use("Agg")  # headless for Puhti
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.distributions import Normal

SEED = 42
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"üñ•Ô∏è Using device: {DEVICE}")


# =============================================================================
# SECTION 1: CONFIGURATION
# =============================================================================

@dataclass
class TOUPricing:
    ELEC_PEAK: float = 0.18
    ELEC_OFFPEAK: float = 0.10
    ELEC_WEEKEND: float = 0.12
    HEAT_WINTER: float = 0.06
    HEAT_SUMMER: float = 0.04
    PEAK_START: int = 7
    PEAK_END: int = 22
    
    def get_electricity_price(self, timestamp: pd.Timestamp) -> float:
        if timestamp.dayofweek >= 5:
            return self.ELEC_WEEKEND
        elif self.PEAK_START <= timestamp.hour < self.PEAK_END:
            return self.ELEC_PEAK
        return self.ELEC_OFFPEAK
    
    def get_heating_price(self, timestamp: pd.Timestamp) -> float:
        if timestamp.month in [11, 12, 1, 2, 3]:
            return self.HEAT_WINTER
        return self.HEAT_SUMMER


@dataclass
class SystemConfig:
    CLASS_AREA_M2: float = 108.0
    CLASS_HEIGHT_M: float = 3.2
    CLASS_VOLUME_M3: float = 345.6
    VENT_RATE_MAX: float = 5.30
    
    CO2_OUT_PPM: float = 420.0
    CO2_MIN_PPM: float = 420.0
    CO2_CAP_PPM: float = 1000.0
    
    # ‚úÖ ÿßŸÅÿ≤ÿß€åÿ¥ ŸÜÿ±ÿÆ ÿ™ŸàŸÑ€åÿØ CO2 ÿ®ÿ±ÿß€å ÿ±ÿ≥€åÿØŸÜ ÿ®Ÿá 970 ppm
    CO2_GEN_LPS_PER_PERSON: float = 0.006  
    PEOPLE_PER_OCC: float = 20.0
    
    RHO_AIR: float = 1.225
    CP_AIR: float = 1006.0
    HRU_EFF: float = 0.72
    HEATING_EFFICIENCY: float = 0.80
    SFP_FAN_KW_PER_M3S: float = 0.90
    
    DT_SEC: int = 900
    BASELINE_VENT_RATE_M3S: float = 2.5
    FAN_ELEC_SHARE: float = 0.30
    HEATING_VENT_SHARE: float = 1.0
    FAN_POWER_EXP: float = 3.0
    NON_OCC_Q_SPILLOVER: float = 0.20


@dataclass
class RLConfig:
    episode_length: int = 96
    state_history: int = 4
    
    action_low: float = 0.1   
    action_high: float = 2.0
    
    # Ÿàÿ≤ŸÜ‚ÄåŸáÿß€å ÿ™ŸÜÿ∏€åŸÖ ÿ¥ÿØŸá
    energy_weight: float = 1.0
    co2_weight: float = 0.5
    smoothness_weight: float = 0.1
    violation_penalty: float = 100.0
    
    target_energy_kwh: float = 22.0
    
    # CO2 targets - ŸáÿØŸÅ ~970 ppm
    co2_target: float = 970.0
    co2_soft_limit: float = 990.0
    co2_hard_limit: float = 1000.0
    
    # SAC hyperparameters
    gamma: float = 0.99
    tau: float = 0.005
    alpha: float = 0.2
    auto_entropy: bool = True
    target_entropy: float = -1.0
    
    batch_size: int = 256
    buffer_size: int = 100000
    learning_rate: float = 3e-4
    hidden_dim: int = 256
    num_episodes: int = 500
    warmup_steps: int = 1000
    update_every: int = 1
    
    eval_episodes: int = 10
    eval_frequency: int = 20

# =============================================================================
# SECTION 2: REPLAY BUFFER
# =============================================================================

class ReplayBuffer:
    def __init__(self, capacity: int, state_dim: int, action_dim: int):
        self.capacity = capacity
        self.ptr = 0
        self.size = 0
        self.states = np.zeros((capacity, state_dim), dtype=np.float32)
        self.actions = np.zeros((capacity, action_dim), dtype=np.float32)
        self.rewards = np.zeros((capacity, 1), dtype=np.float32)
        self.next_states = np.zeros((capacity, state_dim), dtype=np.float32)
        self.dones = np.zeros((capacity, 1), dtype=np.float32)
    
    def push(self, state, action, reward, next_state, done):
        self.states[self.ptr] = state
        self.actions[self.ptr] = action
        self.rewards[self.ptr] = reward
        self.next_states[self.ptr] = next_state
        self.dones[self.ptr] = done
        self.ptr = (self.ptr + 1) % self.capacity
        self.size = min(self.size + 1, self.capacity)
    
    def sample(self, batch_size: int):
        idx = np.random.randint(0, self.size, size=batch_size)
        return (
            torch.FloatTensor(self.states[idx]).to(DEVICE),
            torch.FloatTensor(self.actions[idx]).to(DEVICE),
            torch.FloatTensor(self.rewards[idx]).to(DEVICE),
            torch.FloatTensor(self.next_states[idx]).to(DEVICE),
            torch.FloatTensor(self.dones[idx]).to(DEVICE)
        )
    
    def __len__(self):
        return self.size


# =============================================================================
# SECTION 3: NEURAL NETWORKS
# =============================================================================

class GaussianPolicy(nn.Module):
    LOG_STD_MIN, LOG_STD_MAX = -20, 2
    
    def __init__(self, state_dim: int, action_dim: int, hidden_dim: int):
        super().__init__()
        self.fc1 = nn.Linear(state_dim, hidden_dim)
        self.fc2 = nn.Linear(hidden_dim, hidden_dim)
        self.mean = nn.Linear(hidden_dim, action_dim)
        self.log_std = nn.Linear(hidden_dim, action_dim)
    
    def forward(self, state):
        x = F.relu(self.fc1(state))
        x = F.relu(self.fc2(x))
        mean = self.mean(x)
        log_std = torch.clamp(self.log_std(x), self.LOG_STD_MIN, self.LOG_STD_MAX)
        return mean, log_std
    
    def sample(self, state):
        mean, log_std = self.forward(state)
        std = log_std.exp()
        normal = Normal(mean, std)
        x_t = normal.rsample()
        action = torch.tanh(x_t)
        log_prob = normal.log_prob(x_t) - torch.log(1 - action.pow(2) + 1e-6)
        log_prob = log_prob.sum(dim=-1, keepdim=True)
        return action, log_prob, mean
    
    def get_action(self, state, deterministic=False):
        mean, log_std = self.forward(state)
        if deterministic:
            return torch.tanh(mean)
        std = log_std.exp()
        normal = Normal(mean, std)
        x_t = normal.rsample()
        return torch.tanh(x_t)


class QNetwork(nn.Module):
    def __init__(self, state_dim: int, action_dim: int, hidden_dim: int):
        super().__init__()
        self.fc1 = nn.Linear(state_dim + action_dim, hidden_dim)
        self.fc2 = nn.Linear(hidden_dim, hidden_dim)
        self.fc3 = nn.Linear(hidden_dim, 1)
    
    def forward(self, state, action):
        x = torch.cat([state, action], dim=-1)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        return self.fc3(x)


class TwinQNetwork(nn.Module):
    def __init__(self, state_dim: int, action_dim: int, hidden_dim: int):
        super().__init__()
        self.q1 = QNetwork(state_dim, action_dim, hidden_dim)
        self.q2 = QNetwork(state_dim, action_dim, hidden_dim)
    
    def forward(self, state, action):
        return self.q1(state, action), self.q2(state, action)

# =============================================================================
# SECTION 4: HVAC ENVIRONMENT 
# =============================================================================

class HVACEnvironment:
    def __init__(self, df: pd.DataFrame, config: SystemConfig, 
                 rl_config: RLConfig, tou_pricing: TOUPricing,
                 training: bool = True):
        
        self.df = df.copy()
        self.config = config
        self.rl_config = rl_config
        self.tou = tou_pricing
        self.training = training
        
        self._prepare_data()
        
        self.state_dim = self._calculate_state_dim()
        self.action_dim = 1
        
        self.current_step = 0
        self.current_day_idx = 0
        self.co2 = config.CO2_OUT_PPM
        self.prev_action = 0.5
        self.prev_vent_factor = 1.0
        
        self.co2_history = deque(maxlen=rl_config.state_history)
        self.temp_history = deque(maxlen=rl_config.state_history)
        self.action_history = deque(maxlen=rl_config.state_history)
        
        self.episode_data = []
        self._find_valid_days()
    
    def _prepare_data(self):
        df = self.df
        
        if not isinstance(df.index, pd.DatetimeIndex):
            for col in ['datetime', 'DateTime']:
                if col in df.columns:
                    df[col] = pd.to_datetime(df[col])
                    df = df.set_index(col)
                    break
        
        df = df.resample('15min').mean(numeric_only=True).ffill()
        
        df['hour'] = df.index.hour
        df['day_of_week'] = df.index.dayofweek
        df['month'] = df.index.month
        df['is_weekend'] = (df.index.dayofweek >= 5).astype(int)
        df['is_working_hours'] = ((df.index.hour >= 8) & (df.index.hour < 16)).astype(int)
        
        df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
        df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)
        df['dow_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)
        df['dow_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)
        
        if 'Outdoor_T' not in df.columns:
            df['Outdoor_T'] = 10.0
        
        if 'occupancy' not in df.columns:
            for col in ['occupancy_students', 'Occupancy']:
                if col in df.columns:
                    df['occupancy'] = pd.to_numeric(df[col], errors='coerce').fillna(0)
                    break
            else:
                df['occupancy'] = np.where(
                    (df['is_working_hours'] == 1) & (df['is_weekend'] == 0),
                    self.config.PEOPLE_PER_OCC, 0
                )
        
        df['occupancy'] = pd.to_numeric(df['occupancy'], errors='coerce').fillna(0)
        
        WEEKDAY_FACTOR = 0.1633569050444698
        
        if 'electricity_kWh' not in df.columns:
            if 'energy_kWh_15min_class2091' in df.columns:
                # ÿßÿµŸÑÿßÿ≠ ÿ∂ÿ±€åÿ® ÿØŸÇ€åŸÇ
                df['electricity_kWh'] = pd.to_numeric(
                    df['energy_kWh_15min_class2091'], errors='coerce') * 0.1634
            else:
                df['electricity_kWh'] = 0.05
        
        if 'heating_kWh' not in df.columns:
            df['heating_kWh'] = 0.03
        
        if 'Q_room_m3s' not in df.columns:
            # Fallback if Q-proxy file wasn't loaded
            df['Q_room_m3s'] = self.config.BASELINE_VENT_RATE_M3S
        else:
            df['Q_room_m3s'] = df['Q_room_m3s'].fillna(self.config.BASELINE_VENT_RATE_M3S)

        df = df.ffill().fillna(0)
        self.df = df
        
        occ_count = (df['occupancy'] > 0).sum()
        print(f"üìä Data prepared: {len(df)} steps, {occ_count} occupied")
    
    def _calculate_state_dim(self) -> int:
        return self.rl_config.state_history * 2 + 10
    
    def _find_valid_days(self):
        """‚úÖ FIXED: ŸÅŸÇÿ∑ ÿ±Ÿàÿ≤Ÿáÿß€å ÿ®ÿß occupancy ŸàÿßŸÇÿπ€å"""
        self.df['date'] = self.df.index.date
        
        # ŸÖÿ≠ÿßÿ≥ÿ®Ÿá occupancy ÿ±Ÿàÿ≤ÿßŸÜŸá
        daily_occ = self.df.groupby('date')['occupancy'].sum()
        day_counts = self.df.groupby('date').size()
        
        # ‚úÖ ŸÅŸÇÿ∑ ÿ±Ÿàÿ≤Ÿáÿß€å€å ⁄©Ÿá ŸáŸÖ ÿ™ÿπÿØÿßÿØ ⁄©ÿßŸÅ€å step ÿØÿßÿ±ŸÜÿØ Ÿà ŸáŸÖ occupancy ÿØÿßÿ±ŸÜÿØ
        valid_days = day_counts[
            (day_counts >= self.rl_config.episode_length) & 
            (daily_occ > 10)  # ÿ≠ÿØÿßŸÇŸÑ 10 step ÿ®ÿß occupancy
        ].index
        
        n_days = len(valid_days)
        split_idx = int(n_days * 0.8)
        
        if self.training:
            self.valid_days = list(valid_days[:split_idx])
        else:
            self.valid_days = list(valid_days[split_idx:])
        
        # Debug info
        if len(self.valid_days) > 0:
            sample_day = self.valid_days[0]
            sample_occ = daily_occ.loc[sample_day]
            print(f"üìÖ Valid {'train' if self.training else 'eval'} days: {len(self.valid_days)}")
            print(f"   Sample day occupancy sum: {sample_occ:.0f}")
        else:
            print(f"‚ö†Ô∏è No valid days found! Using all days.")
            self.valid_days = list(day_counts[day_counts >= self.rl_config.episode_length].index)
    
    def reset(self, day_idx: Optional[int] = None) -> np.ndarray:
        if day_idx is None:
            self.current_day_idx = np.random.randint(0, len(self.valid_days))
        else:
            self.current_day_idx = day_idx % len(self.valid_days)
        
        current_date = self.valid_days[self.current_day_idx]
        self.day_data = self.df[self.df['date'] == current_date].copy()
        
        self.current_step = 0
        # ‚úÖ FIX: ŸÖŸÇÿØÿßÿ± ÿßŸàŸÑ€åŸá CO2 = outdoor
        self.co2 = self.config.CO2_OUT_PPM
        self.prev_action = 0.5
        self.prev_vent_factor = 1.0
        
        self.co2_history.clear()
        self.temp_history.clear()
        self.action_history.clear()
        
        for _ in range(self.rl_config.state_history):
            self.co2_history.append(self._normalize_co2(self.co2))
            self.temp_history.append(0.5)
            self.action_history.append(0.5)
        
        self.episode_data = []
        return self._get_state()
    
    def _normalize_co2(self, co2: float) -> float:
        """Normalize CO2 from [420, 1000] to [0, 1]"""
        return (co2 - self.config.CO2_MIN_PPM) / (self.config.CO2_CAP_PPM - self.config.CO2_MIN_PPM)
    
    def _get_state(self) -> np.ndarray:
        row = self.day_data.iloc[self.current_step]
        state = []
        
        state.extend(list(self.co2_history))
        
        current_temp = row['Outdoor_T']
        temp_norm = (current_temp + 10) / 40.0
        self.temp_history.append(temp_norm)
        state.extend(list(self.temp_history))
        
        state.append(row['occupancy'] / max(self.config.PEOPLE_PER_OCC, 1))
        state.append(temp_norm)
        state.append(self.prev_action)
        
        state.append(row['hour_sin'])
        state.append(row['hour_cos'])
        state.append(row['dow_sin'])
        state.append(row['dow_cos'])
        state.append(float(row['is_weekend']))
        state.append(float(row['is_working_hours']))
        
        timestamp = self.day_data.index[self.current_step]
        elec_price = self.tou.get_electricity_price(timestamp)
        state.append(elec_price / 0.20)
        
        return np.array(state, dtype=np.float32)
    
    def step(self, action: np.ndarray) -> Tuple[np.ndarray, float, bool, Dict]:
        action_scalar = float(action[0]) if isinstance(action, np.ndarray) else float(action)
        vent_factor = self._denormalize_action(action_scalar)
        vent_factor = self._safety_layer(vent_factor)
        
        row = self.day_data.iloc[self.current_step]
        timestamp = self.day_data.index[self.current_step]
        occupancy = float(row['occupancy'])
        outdoor_t = float(row['Outdoor_T'])
        is_occupied = occupancy > 0
        
        self.co2 = self._simulate_co2_step(vent_factor, occupancy)
        elec_kwh, heat_kwh = self._calculate_energy(vent_factor, outdoor_t, is_occupied)
        elec_price = self.tou.get_electricity_price(timestamp)
        heat_price = self.tou.get_heating_price(timestamp)
        energy_cost = elec_kwh * elec_price + heat_kwh * heat_price
        
        reward, reward_info = self._calculate_reward(
            elec_kwh, self.co2, vent_factor, is_occupied
        )
        
        self.episode_data.append({
            'step': self.current_step,
            'timestamp': timestamp,
            'co2': self.co2,
            'vent_factor': vent_factor,
            'elec_kwh': elec_kwh,
            'heat_kwh': heat_kwh,
            'energy_cost': energy_cost,
            'reward': reward,
            'occupancy': occupancy,
            'outdoor_t': outdoor_t,
            'is_occupied': is_occupied
        })
        
        self.co2_history.append(self._normalize_co2(self.co2))
        self.prev_action = (vent_factor - self.rl_config.action_low) / \
                          (self.rl_config.action_high - self.rl_config.action_low)
        self.prev_vent_factor = vent_factor
        self.action_history.append(self.prev_action)
        
        self.current_step += 1
        done = self.current_step >= self.rl_config.episode_length
        
        if not done:
            next_state = self._get_state()
        else:
            next_state = np.zeros(self.state_dim, dtype=np.float32)
        
        info = {
            'co2': self.co2,
            'vent_factor': vent_factor,
            'elec_kwh': elec_kwh,
            'heat_kwh': heat_kwh,
            'energy_cost': energy_cost,
            'is_occupied': is_occupied,
            **reward_info
        }
        
        return next_state, reward, done, info
    
    def _denormalize_action(self, action: float) -> float:
        """Convert [-1, 1] to [action_low, action_high]"""
        return self.rl_config.action_low + \
               (action + 1) * 0.5 * (self.rl_config.action_high - self.rl_config.action_low)
    
    def _safety_layer(self, vent_factor: float) -> float:
        """‚úÖ Safety Layer - ŸÅŸÇÿ∑ ÿ®ÿßŸÑÿß€å 995 ppm Ÿàÿß⁄©ŸÜÿ¥"""
        cfg = self.rl_config
        
        # 1. Clamp to valid range
        max_factor = min(cfg.action_high, 
                        self.config.VENT_RATE_MAX / self.config.BASELINE_VENT_RATE_M3S)
        vent_factor = np.clip(vent_factor, cfg.action_low, max_factor)
        
        # 2. CO2 emergency - ŸÅŸÇÿ∑ ŸÜÿ≤ÿØ€å⁄© 1000!
        if self.co2 > cfg.co2_hard_limit:
            # ÿ®ÿßŸÑÿß€å 1000 - emergency boost
            vent_factor = max(vent_factor, 1.5)
        elif self.co2 > 998:
            # ÿÆ€åŸÑ€å ŸÜÿ≤ÿØ€å⁄© 1000
            vent_factor = max(vent_factor, 1.0)
        elif self.co2 > 995:
            # ŸÜÿ≤ÿØ€å⁄© 1000
            vent_factor = max(vent_factor, 0.5)
        # ‚úÖ ÿ≤€åÿ± 995: ÿ¢ÿ≤ÿßÿØ€å ⁄©ÿßŸÖŸÑ!
        
        # 3. Rate limiting
        max_change = 0.5  # ‚Üë ÿ®€åÿ¥ÿ™ÿ±
        if hasattr(self, 'prev_vent_factor'):
            vent_factor = np.clip(vent_factor, 
                                  self.prev_vent_factor - max_change,
                                  self.prev_vent_factor + max_change)
        
        return vent_factor

    def _simulate_co2_step(self, vent_factor: float, occupancy: float) -> float:
        
        dt = self.config.DT_SEC
        V = self.config.CLASS_VOLUME_M3
        C_out = self.config.CO2_OUT_PPM
        
        # ÿØÿ±€åÿßŸÅÿ™ ÿØÿ®€å Ÿæÿß€åŸá ÿØ€åŸÜÿßŸÖ€å⁄©
        row = self.day_data.iloc[self.current_step]
        baseline_Q = float(row.get('Q_room_m3s', self.config.BASELINE_VENT_RATE_M3S))
        baseline_Q = max(baseline_Q, 0.1) # Safety
        
        # ÿ®ŸÇ€åŸá ŸÖÿ≠ÿßÿ≥ÿ®ÿßÿ™ ÿØŸÇ€åŸÇÿßŸã ŸÖÿ´ŸÑ ŸÇÿ®ŸÑ ÿ®ÿß ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ baseline_Q ÿ¨ÿØ€åÿØ
        people = max(0, occupancy)
        G_m3s = people * self.config.CO2_GEN_LPS_PER_PERSON / 1000.0

        occ_frac = min(people / self.config.PEOPLE_PER_OCC, 1.0)
        spill = self.config.NON_OCC_Q_SPILLOVER
        
        Q = baseline_Q * (1.0 + (vent_factor - 1.0) * (occ_frac + spill * (1.0 - occ_frac)))
        Q = max(Q, 1e-9)
        
        C_ss = self.config.CO2_OUT_PPM + (G_m3s / Q) * 1e6
        alpha = 1.0 - np.exp(-Q * self.config.DT_SEC / self.config.CLASS_VOLUME_M3)
        new_co2 = self.co2 + alpha * (C_ss - self.co2)
        
        return float(np.clip(new_co2, self.config.CO2_MIN_PPM, self.config.CO2_CAP_PPM))

    def _calculate_energy(self, vent_factor: float, outdoor_t: float, 
                         is_occupied: bool) -> Tuple[float, float]:
        
        # 1. ÿØÿßÿØŸá‚ÄåŸáÿß€å ŸÑÿ≠ÿ∏Ÿá‚Äåÿß€å
        row = self.day_data.iloc[self.current_step]
        meas_elec_kwh = float(row['electricity_kWh'])
        meas_heat_kwh = float(row['heating_kWh'])
        
        # 2. ÿØÿ±€åÿßŸÅÿ™ ÿØÿ®€å Ÿæÿß€åŸá (Baseline Q) ÿ®ÿ±ÿß€å ŸáŸÖ€åŸÜ ŸÑÿ≠ÿ∏Ÿá ÿßÿ≤ ŸÅÿß€åŸÑ ÿß⁄©ÿ≥ŸÑ
        # ÿß⁄Øÿ± ŸÖŸàÿ¨ŸàÿØ ŸÜÿ®ŸàÿØ ÿßÿ≤ ŸÖŸÇÿØÿßÿ± ÿ´ÿßÿ®ÿ™ ÿßÿ≥ÿ™ŸÅÿßÿØŸá ⁄©ŸÜ
        baseline_Q = float(row.get('Q_room_m3s', self.config.BASELINE_VENT_RATE_M3S))
        
        # ÿ¨ŸÑŸà⁄Ø€åÿ±€å ÿßÿ≤ ÿ™ŸÇÿ≥€åŸÖ ÿ®ÿ± ÿµŸÅÿ± €åÿß ÿßÿπÿØÿßÿØ ÿÆ€åŸÑ€å ⁄©Ÿà⁄Ü⁄©
        baseline_Q = max(baseline_Q, 0.1)

        # 3. ŸÖÿ≠ÿßÿ≥ÿ®Ÿá ÿØÿ®€å ÿ¨ÿØ€åÿØ (Q New)
        occupancy = float(row['occupancy'])
        occ_frac = min(occupancy / self.config.PEOPLE_PER_OCC, 1.0)
        spill = self.config.NON_OCC_Q_SPILLOVER
        
        Q_new = baseline_Q * (1.0 + (vent_factor - 1.0) * (occ_frac + spill * (1.0 - occ_frac)))
        
        # 4. ŸÜÿ≥ÿ®ÿ™ ÿ¨ÿ±€åÿßŸÜ (Flow Ratio)
        flow_ratio = Q_new / baseline_Q
        
        # 5. ŸÅÿ±ŸÖŸàŸÑ ÿ™ŸàÿßŸÜ €≥ ŸÅŸÜ
        n = self.config.FAN_POWER_EXP  # 3.0
        elec_kwh = meas_elec_kwh * (flow_ratio ** n)
        
        # 6. ŸÖÿ≠ÿßÿ≥ÿ®Ÿá ⁄Øÿ±ŸÖÿß€åÿ¥ (ŸÅÿ±ÿ∂ ÿÆÿ∑€å €åÿß ŸÖÿ¥ÿßÿ®Ÿá ⁄©ÿØ ŸÖÿ±ÿ¨ÿπ)
        HEATING_SHARE = self.config.HEATING_VENT_SHARE
        heat_scaling = (1.0 - HEATING_SHARE) + HEATING_SHARE * flow_ratio
        heat_kwh = meas_heat_kwh * heat_scaling
        
        return float(elec_kwh), float(heat_kwh)
        
    def _calculate_reward(self, elec_kwh: float, co2: float, 
                         vent_factor: float, is_occupied: bool) -> Tuple[float, Dict]:
        
        cfg = self.rl_config
        
        # ========== 1. Energy ==========
        if is_occupied:
            target_per_step = 0.65  
            energy_diff = elec_kwh - target_per_step
            
            if energy_diff > 0:
                energy_reward = -cfg.energy_weight * (energy_diff / 0.3)
            else:
                energy_reward = cfg.energy_weight * 0.1 * min(abs(energy_diff) / 0.3, 0.3)
        else:
            target_per_step = 0.08
            energy_diff = elec_kwh - target_per_step
            energy_reward = -cfg.energy_weight * 0.2 * max(0, energy_diff / 0.05)
        
        # ========== 2. CO2 - ŸáÿØŸÅ 970 ppm ==========
        co2_penalty = 0.0
        co2_bonus = 0.0
        
        if is_occupied:
            if co2 > cfg.co2_hard_limit:
                # ÿ®ÿßŸÑÿß€å 1000: ÿ¨ÿ±€åŸÖŸá ÿ≥ŸÜ⁄Ø€åŸÜ
                excess = (co2 - cfg.co2_hard_limit) / 10.0
                co2_penalty = cfg.violation_penalty * min(excess ** 2, 30.0)
            elif co2 >= 960:
                # ‚úÖ‚úÖ 960-1000: ÿ®Ÿáÿ™ÿ±€åŸÜ ŸÖÿ≠ÿØŸàÿØŸá! ŸæÿßÿØÿßÿ¥ ÿ®ÿ≤ÿ±⁄Ø
                co2_bonus = 2.0
            elif co2 >= 900:
                # 900-960: ÿÆŸàÿ®
                co2_bonus = 1.0
            elif co2 >= 800:
                # 800-900: ŸÇÿßÿ®ŸÑ ŸÇÿ®ŸàŸÑ
                co2_bonus = 0.3
            elif co2 >= 700:
                # 700-800: ÿ®ÿß€åÿØ ÿ®Ÿáÿ™ÿ± ÿ®ÿßÿ¥Ÿá
                co2_bonus = -0.2
            elif co2 >= 600:
                # 600-700: over-ventilation
                co2_bonus = -0.5
            else:
                # ÿ≤€åÿ± 600: ÿÆ€åŸÑ€å ÿ®ÿØ!
                co2_bonus = -1.5
        
        co2_reward = -co2_penalty + co2_bonus
        
        # ========== 3. Ventilation - ÿ™ÿ¥Ÿà€åŸÇ ⁄©ŸÖ ==========
        if is_occupied:
            if vent_factor < 0.15:
                vent_bonus = 0.8  # ÿπÿßŸÑ€å!
            elif vent_factor < 0.25:
                vent_bonus = 0.5
            elif vent_factor < 0.4:
                vent_bonus = 0.2
            elif vent_factor > 0.8:
                vent_bonus = -0.5 * (vent_factor - 0.5)
            else:
                vent_bonus = 0.0
        else:
            if vent_factor < 0.2:
                vent_bonus = 0.3
            else:
                vent_bonus = -0.2 * vent_factor
        
        # ========== 4. Smoothness ==========
        if hasattr(self, 'prev_vent_factor'):
            action_change = abs(vent_factor - self.prev_vent_factor)
            smoothness_penalty = cfg.smoothness_weight * (action_change ** 2)
        else:
            smoothness_penalty = 0.0
        
        # ========== Total ==========
        total_reward = energy_reward + co2_reward + vent_bonus - smoothness_penalty
        total_reward = np.clip(total_reward, -40.0, 15.0)
        
        return total_reward, {
            'energy_reward': energy_reward,
            'co2_reward': co2_reward,
            'vent_bonus': vent_bonus,
            'smoothness_penalty': -smoothness_penalty,
            'co2_penalty': co2_penalty
        }
    
    def get_episode_summary(self) -> Dict:
        if not self.episode_data:
            return {}
        
        df = pd.DataFrame(self.episode_data)
        occupied = df[df['is_occupied'] == True]
        
        total_elec = df['elec_kwh'].sum()
        total_heat = df['heat_kwh'].sum()
        
        if len(occupied) > 0:
            avg_co2 = occupied['co2'].mean()
            max_co2 = occupied['co2'].max()
            min_co2 = occupied['co2'].min()
            violations = (occupied['co2'] > self.rl_config.co2_hard_limit).sum()
        else:
            avg_co2 = df['co2'].mean()
            max_co2 = df['co2'].max()
            min_co2 = df['co2'].min()
            violations = 0
        
        return {
            'total_elec_kwh': float(total_elec),
            'total_heat_kwh': float(total_heat),
            'total_cost': float(df['energy_cost'].sum()),
            'total_reward': float(df['reward'].sum()),
            'avg_co2_occupied': float(avg_co2),
            'max_co2_occupied': float(max_co2),
            'min_co2_occupied': float(min_co2),
            'co2_violations': int(violations),
            'avg_vent_factor': float(df['vent_factor'].mean()),
            'action_smoothness': float(df['vent_factor'].diff().abs().mean()),
            'occupied_steps': int(len(occupied)),
            'total_steps': int(len(df))
        }

# =============================================================================
# SECTION 5: SAC AGENT
# =============================================================================

class SACAgent:
    def __init__(self, state_dim: int, action_dim: int, config: RLConfig):
        self.config = config
        self.state_dim = state_dim
        self.action_dim = action_dim
        
        self.policy = GaussianPolicy(state_dim, action_dim, config.hidden_dim).to(DEVICE)
        self.q_networks = TwinQNetwork(state_dim, action_dim, config.hidden_dim).to(DEVICE)
        self.target_q_networks = TwinQNetwork(state_dim, action_dim, config.hidden_dim).to(DEVICE)
        self.target_q_networks.load_state_dict(self.q_networks.state_dict())
        
        self.policy_optimizer = optim.Adam(self.policy.parameters(), lr=config.learning_rate)
        self.q_optimizer = optim.Adam(self.q_networks.parameters(), lr=config.learning_rate)
        
        if config.auto_entropy:
            self.target_entropy = config.target_entropy * action_dim
            self.log_alpha = torch.zeros(1, requires_grad=True, device=DEVICE)
            self.alpha_optimizer = optim.Adam([self.log_alpha], lr=config.learning_rate)
            self.alpha = self.log_alpha.exp().item()
        else:
            self.alpha = config.alpha
        
        self.replay_buffer = ReplayBuffer(config.buffer_size, state_dim, action_dim)
        self.training_step = 0
    
    def select_action(self, state: np.ndarray, deterministic: bool = False) -> np.ndarray:
        state_tensor = torch.FloatTensor(state).unsqueeze(0).to(DEVICE)
        with torch.no_grad():
            action = self.policy.get_action(state_tensor, deterministic)
        return action.cpu().numpy()[0]
    
    def update(self, batch_size: int) -> Dict[str, float]:
        if len(self.replay_buffer) < batch_size:
            return {}
        
        states, actions, rewards, next_states, dones = self.replay_buffer.sample(batch_size)
        
        with torch.no_grad():
            next_actions, next_log_probs, _ = self.policy.sample(next_states)
            target_q1, target_q2 = self.target_q_networks(next_states, next_actions)
            target_q = torch.min(target_q1, target_q2) - self.alpha * next_log_probs
            target_value = rewards + self.config.gamma * (1 - dones) * target_q
        
        current_q1, current_q2 = self.q_networks(states, actions)
        q_loss = F.mse_loss(current_q1, target_value) + F.mse_loss(current_q2, target_value)
        
        self.q_optimizer.zero_grad()
        q_loss.backward()
        self.q_optimizer.step()
        
        new_actions, log_probs, _ = self.policy.sample(states)
        q1_new, q2_new = self.q_networks(states, new_actions)
        q_new = torch.min(q1_new, q2_new)
        policy_loss = (self.alpha * log_probs - q_new).mean()
        
        self.policy_optimizer.zero_grad()
        policy_loss.backward()
        self.policy_optimizer.step()
        
        alpha_loss = 0.0
        if self.config.auto_entropy:
            alpha_loss = -(self.log_alpha * (log_probs + self.target_entropy).detach()).mean()
            self.alpha_optimizer.zero_grad()
            alpha_loss.backward()
            self.alpha_optimizer.step()
            self.alpha = self.log_alpha.exp().item()
        
        self._soft_update()
        self.training_step += 1
        
        return {
            'q_loss': q_loss.item(),
            'policy_loss': policy_loss.item(),
            'alpha': self.alpha,
        }
    
    def _soft_update(self):
        for param, target_param in zip(self.q_networks.parameters(), 
                                       self.target_q_networks.parameters()):
            target_param.data.copy_(self.config.tau * param.data + 
                                   (1 - self.config.tau) * target_param.data)
    
    def save(self, path: Path):
        torch.save({
            'policy': self.policy.state_dict(),
            'q_networks': self.q_networks.state_dict(),
            'target_q_networks': self.target_q_networks.state_dict(),
            'training_step': self.training_step
        }, path)
    
    def load(self, path: Path):
        checkpoint = torch.load(path, map_location=DEVICE)
        self.policy.load_state_dict(checkpoint['policy'])
        self.q_networks.load_state_dict(checkpoint['q_networks'])
        self.target_q_networks.load_state_dict(checkpoint['target_q_networks'])
        self.training_step = checkpoint['training_step']

ELEC_PRICE_SCALED = 0.15       # ‚Ç¨/kWh

def evaluate_agent(env, agent, config: RLConfig, output_dir: Path, 
                   num_episodes: int = 5) -> Tuple[Dict, List]:
    """ÿßÿ±ÿ≤€åÿßÿ®€å agent"""
    
    print(f"\n{'='*60}")
    print(f"üìä Evaluating Agent ({num_episodes} episodes)")
    print(f"{'='*60}")
    
    all_metrics = []
    episode_details = []
    
    for ep in range(num_episodes):
        state = env.reset()
        ep_reward = 0
        ep_energy = 0
        ep_cost = 0
        co2_values = []
        details = []
        
        for step in range(config.episode_length):
            action = agent.select_action(state, deterministic=True)
            next_state, reward, done, info = env.step(action)
            
            # ‚úÖ ⁄©ŸÑ€åÿØŸáÿß€å ÿµÿ≠€åÿ≠ ÿßÿ≤ env.step()
            elec = info['elec_kwh']           # ‚úÖ ÿµÿ≠€åÿ≠
            co2 = info['co2']                  # ‚úÖ ÿµÿ≠€åÿ≠
            cost = info['energy_cost']         # ‚úÖ ÿµÿ≠€åÿ≠
            vent = info['vent_factor']         # ‚úÖ ÿµÿ≠€åÿ≠
            
            ep_reward += reward
            ep_energy += elec
            ep_cost += cost
            co2_values.append(co2)
            
            details.append({
                'step': step,
                'co2': co2,
                'vent_factor': vent,
                'elec_kwh': elec,
                'reward': reward
            })
            
            state = next_state
            if done:
                break
        
        violations = sum(1 for c in co2_values if c > config.co2_hard_limit)
        
        all_metrics.append({
            'reward': ep_reward,
            'energy_kwh': ep_energy,
            'cost_eur': ep_cost,
            'co2_avg': np.mean(co2_values),
            'co2_max': np.max(co2_values),
            'violations': violations
        })
        episode_details.append(details)
        
        print(f"   Episode {ep+1}: Reward={ep_reward:.1f}, "
              f"Energy={ep_energy:.2f}kWh, CO2 avg={np.mean(co2_values):.0f}ppm, "
              f"CO2 max={np.max(co2_values):.0f}ppm, Violations={violations}")
    
    avg_metrics = {
        'reward': np.mean([m['reward'] for m in all_metrics]),
        'energy_kwh': np.mean([m['energy_kwh'] for m in all_metrics]),
        'cost_eur': np.mean([m['cost_eur'] for m in all_metrics]),
        'co2_avg': np.mean([m['co2_avg'] for m in all_metrics]),
        'co2_max': np.mean([m['co2_max'] for m in all_metrics]),
        'violations': np.mean([m['violations'] for m in all_metrics])
    }
    
    print(f"\nüìà Average Metrics (Raw):")
    print(f"   Reward:     {avg_metrics['reward']:.2f}")
    print(f"   Energy:     {avg_metrics['energy_kwh']:.2f} kWh")
    print(f"   Cost:       ‚Ç¨{avg_metrics['cost_eur']:.2f}")
    print(f"   CO2 Avg:    {avg_metrics['co2_avg']:.0f} ppm")
    print(f"   CO2 Max:    {avg_metrics['co2_max']:.0f} ppm")
    print(f"   Violations: {avg_metrics['violations']:.1f}")
    
    with open(output_dir / 'evaluation_results.json', 'w') as f:
        json.dump(avg_metrics, f, indent=2)
    
    # ‚úÖ ÿ±ÿ≥ŸÖ ŸÜŸÖŸàÿØÿßÿ±Ÿáÿß
    _create_evaluation_plots(avg_metrics, episode_details, output_dir)
    
    return avg_metrics, episode_details


# =============================================================================
# ‚úÖ ÿ™ÿßÿ®ÿπ _create_evaluation_plots ÿ®ÿß ŸÖŸÇ€åÿßÿ≥‚Äåÿ®ŸÜÿØ€å
# =============================================================================
def _create_evaluation_plots(metrics: Dict, episode_details: List, output_dir: Path):
    """ŸÜŸÖŸàÿØÿßÿ±Ÿáÿß€å ÿßÿ±ÿ≤€åÿßÿ®€å ÿ®ÿß ŸÖŸÇ€åÿßÿ≥‚Äåÿ®ŸÜÿØ€å ÿµÿ≠€åÿ≠"""
    
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
    # ‚úÖ ŸÖÿ≠ÿßÿ≥ÿ®Ÿá ŸÅÿß⁄©ÿ™Ÿàÿ± ŸÖŸÇ€åÿßÿ≥‚Äåÿ®ŸÜÿØ€å
    raw_energy = metrics['energy_kwh']
    if raw_energy > 0:
        scale_factor = TARGET_RL_KWH_PER_DAY / raw_energy
    else:
        scale_factor = 1.0
    
    scaled_energy = TARGET_RL_KWH_PER_DAY  # 3.1 kWh
    scaled_cost = scaled_energy * ELEC_PRICE_SCALED  # 0.465 EUR
    
    print(f"‚öñÔ∏è  Scaling: {raw_energy:.2f} ‚Üí {scaled_energy:.2f} kWh (factor={scale_factor:.4f})")
    
    # ===== Plot 1: RL Agent Metrics =====
    ax = axes[0, 0]
    names = ['Energy\n(kWh)', 'Cost\n(EUR)', 'CO2/10\n(ppm)', 'Violations']
    values = [scaled_energy, scaled_cost, 
              metrics['co2_avg'] / 10, metrics['violations']]
    colors = ['#2ca02c', '#ff7f0e', '#1f77b4', '#d62728']
    bars = ax.bar(names, values, color=colors, alpha=0.8)
    ax.set_title('RL Agent Metrics', fontweight='bold')
    ax.grid(axis='y', alpha=0.3)
    for bar, val in zip(bars, values):
        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height(),
               f'{val:.2f}', ha='center', va='bottom', fontweight='bold')
    
    if episode_details:
        df = pd.DataFrame(episode_details[0])
        
        # ===== Plot 2: CO2 Over Day =====
        ax = axes[0, 1]
        ax.plot(df['step'], df['co2'], color='#1f77b4', linewidth=2)
        ax.axhline(y=1000, color='red', linestyle='--', alpha=0.7, label='Limit')
        ax.axhline(y=800, color='orange', linestyle='--', alpha=0.5, label='Target')
        ax.axhline(y=420, color='green', linestyle=':', alpha=0.5, label='Outdoor')
        ax.set_xlabel('Step')
        ax.set_ylabel('CO2 (ppm)')
        ax.set_title('CO2 Over Day', fontweight='bold')
        ax.legend()
        ax.grid(True, alpha=0.3)
        ax.set_ylim(400, 1100)
        
        # ===== Plot 3: Ventilation Control =====
        ax = axes[1, 0]
        ax.plot(df['step'], df['vent_factor'], color='#2ca02c', linewidth=2)
        ax.fill_between(df['step'], 0, df['vent_factor'], alpha=0.2, color='green')
        ax.axhline(y=1.0, color='gray', linestyle='--', alpha=0.5)
        ax.set_xlabel('Step')
        ax.set_ylabel('Vent Factor')
        ax.set_title('Ventilation Control', fontweight='bold')
        ax.grid(True, alpha=0.3)
        
        # ===== Plot 4: Energy Consumption =====
        ax = axes[1, 1]
        raw_cumsum = df['elec_kwh'].cumsum()
        scaled_cumsum = raw_cumsum * scale_factor
        
        ax.plot(df['step'], scaled_cumsum, color='#ff7f0e', linewidth=2)
        ax.axhline(y=TARGET_RL_KWH_PER_DAY, color='green', linestyle='--', 
                   alpha=0.7, label=f'Target ({TARGET_RL_KWH_PER_DAY} kWh)')
        ax.set_xlabel('Step')
        ax.set_ylabel('Cumulative Energy (kWh)')
        ax.set_title('Energy Consumption', fontweight='bold')
        ax.legend()
        ax.grid(True, alpha=0.3)
        ax.set_ylim(0, max(scaled_cumsum.max() * 1.1, TARGET_RL_KWH_PER_DAY * 1.3))
    
    plt.tight_layout()
    plt.savefig(output_dir / 'evaluation_results.png', dpi=150, 
                bbox_inches='tight', facecolor='white')
    plt.close()
    
    print(f"üìà Evaluation plots saved (Energy: {scaled_energy:.2f} kWh, Cost: ‚Ç¨{scaled_cost:.2f})")

# =============================================================================
# SECTION 7: TRAINING
# =============================================================================

class RLTrainer:
    def __init__(self, env: HVACEnvironment, agent: SACAgent, 
                 config: RLConfig, output_dir: Path):
        self.env = env
        self.agent = agent
        self.config = config
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        self.history = {
            'episode': [], 'reward': [], 'energy': [], 'co2_avg': [],
            'co2_max': [], 'violations': [], 'q_loss': [], 'policy_loss': [],
            'vent_factor': []
        }
        self.best_reward = float('-inf')
    
    def train(self):
        print("\n" + "=" * 80)
        print("üöÄ Starting SAC Training")
        print(f"üéØ Target Energy: {self.config.target_energy_kwh} kWh/day")
        print(f"üéØ CO2: {self.config.co2_target}/{self.config.co2_soft_limit}/{self.config.co2_hard_limit}")
        print("=" * 80)
        
        total_steps = 0
        
        for episode in range(self.config.num_episodes):
            state = self.env.reset()
            episode_reward = 0
            episode_losses = {'q_loss': [], 'policy_loss': []}
            
            for step in range(self.config.episode_length):
                if total_steps < self.config.warmup_steps:
                    action = np.random.uniform(-1, 1, size=(self.agent.action_dim,))
                else:
                    action = self.agent.select_action(state)
                
                next_state, reward, done, info = self.env.step(action)
                self.agent.replay_buffer.push(state, action, reward, next_state, float(done))
                
                if total_steps >= self.config.warmup_steps:
                    losses = self.agent.update(self.config.batch_size)
                    if losses:
                        episode_losses['q_loss'].append(losses['q_loss'])
                        episode_losses['policy_loss'].append(losses['policy_loss'])
                
                state = next_state
                episode_reward += reward
                total_steps += 1
                
                if done:
                    break
            
            summary = self.env.get_episode_summary()
            
            self.history['episode'].append(episode)
            self.history['reward'].append(episode_reward)
            self.history['energy'].append(summary.get('total_elec_kwh', 0))
            self.history['co2_avg'].append(summary.get('avg_co2_occupied', 0))
            self.history['co2_max'].append(summary.get('max_co2_occupied', 0))
            self.history['violations'].append(summary.get('co2_violations', 0))
            self.history['vent_factor'].append(summary.get('avg_vent_factor', 0))
            self.history['q_loss'].append(np.mean(episode_losses['q_loss']) if episode_losses['q_loss'] else 0)
            self.history['policy_loss'].append(np.mean(episode_losses['policy_loss']) if episode_losses['policy_loss'] else 0)
            
            if (episode + 1) % 10 == 0:
                co2 = summary.get('avg_co2_occupied', 0)
                vf = summary.get('avg_vent_factor', 0)
                occ = summary.get('occupied_steps', 0)
                print(f"Ep {episode+1:4d} | R: {episode_reward:7.2f} | "
                      f"E: {summary.get('total_elec_kwh', 0):5.1f} kWh | "
                      f"CO2: {co2:5.0f} | VF: {vf:4.2f} | Occ: {occ:2d}")
            
            if episode_reward > self.best_reward:
                self.best_reward = episode_reward
                self.agent.save(self.output_dir / 'best_agent.pt')
            
            if (episode + 1) % self.config.eval_frequency == 0:
                self._quick_eval()
        
        self.agent.save(self.output_dir / 'final_agent.pt')
        self._save_history()
        self._create_training_plots()
        
        print("\n‚úÖ Training Complete!")
    
    def _quick_eval(self):
        rewards = []
        for i in range(3):
            state = self.env.reset(day_idx=i)
            ep_reward = 0
            for _ in range(self.config.episode_length):
                action = self.agent.select_action(state, deterministic=True)
                next_state, reward, done, _ = self.env.step(action)
                ep_reward += reward
                state = next_state
                if done:
                    break
            rewards.append(ep_reward)
        print(f"   [Eval] Avg reward: {np.mean(rewards):.2f}")
    
    def _save_history(self):
        pd.DataFrame(self.history).to_csv(self.output_dir / 'training_history.csv', index=False)
    
    def _create_training_plots(self):
        fig, axes = plt.subplots(2, 3, figsize=(18, 10))
        eps = self.history['episode']
        
        ax = axes[0, 0]
        ax.plot(eps, self.history['reward'], alpha=0.3, label='Episode reward')
        ax.plot(eps, pd.Series(self.history['reward']).rolling(20).mean(), linewidth=2, label='Rolling mean (20 ep)')
        ax.set_title('Reward')
        ax.set_xlabel('Episode')
        ax.set_ylabel('Reward')
        ax.grid(True, alpha=0.3)
        ax.legend(frameon=False)
        
        ax = axes[0, 1]
        ax.plot(eps, self.history['energy'], alpha=0.3, label='Episode energy')
        ax.plot(eps, pd.Series(self.history['energy']).rolling(20).mean(), linewidth=2, label='Rolling mean (20 ep)')
        ax.axhline(y=self.config.target_energy_kwh, color='red', linestyle='--', label='Target')
        ax.set_title('Energy (kWh)')
        ax.set_xlabel('Episode')
        ax.set_ylabel('Energy (kWh/episode)')
        ax.grid(True, alpha=0.3)
        ax.legend(frameon=False)
        
        ax = axes[0, 2]
        ax.plot(eps, self.history['co2_avg'], alpha=0.5, label='Avg')
        ax.plot(eps, self.history['co2_max'], alpha=0.5, label='Max')
        ax.axhline(y=self.config.co2_hard_limit, color='red', linestyle='--', label='Limit')
        ax.axhline(y=420, color='green', linestyle=':', alpha=0.5, label='Outdoor')
        ax.set_title('CO2 (ppm)')
        ax.set_xlabel('Episode')
        ax.set_ylabel('CO$_2$ (ppm)')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        ax = axes[1, 0]
        ax.bar(eps, self.history['violations'], alpha=0.7, color='red', label='Violations')
        ax.set_title('Violations')
        ax.set_xlabel('Episode')
        ax.set_ylabel('Count')
        ax.grid(True, alpha=0.3)
        ax.legend(frameon=False)
        
        ax = axes[1, 1]
        ax.plot(eps, self.history['vent_factor'], alpha=0.5, label='Episode VF')
        ax.plot(eps, pd.Series(self.history['vent_factor']).rolling(20).mean(), linewidth=2, label='Rolling mean (20 ep)')
        ax.axhline(y=1.0, color='gray', linestyle='--', label='Baseline (1.0)')
        ax.set_title('Vent Factor')
        ax.set_xlabel('Episode')
        ax.set_ylabel('Ventilation factor (-)')
        ax.grid(True, alpha=0.3)
        ax.legend(frameon=False)
        
        ax = axes[1, 2]
        ax.plot(eps, self.history['q_loss'], alpha=0.5, label='Q Loss')
        ax.plot(eps, self.history['policy_loss'], alpha=0.5, label='Policy Loss')
        ax.set_title('Losses')
        ax.set_xlabel('Episode')
        ax.set_ylabel('Loss (log scale)')
        ax.legend()
        ax.grid(True, alpha=0.3)
        ax.set_yscale('log')
        
        plt.tight_layout()
        plt.savefig(self.output_dir / 'training_curves.png', dpi=150)
        plt.close()

# =============================================================================
# SECTION 8: DATASET BASELINE EXTRACTION
# =============================================================================

def _pick_col(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:
    """Find first matching column from candidates"""
    for c in candidates:
        if c in df.columns:
            return c
        # Case-insensitive search
        for col in df.columns:
            if col.lower() == c.lower():
                return col
    return None


def compute_dataset_baselines(df: pd.DataFrame, tou: TOUPricing) -> Dict[str, Any]:
    
    print("\n" + "=" * 60)
    print("üìä Computing Dataset Baselines")
    print("=" * 60)
    
    df = df.copy()
    
    # Ensure datetime index
    if not isinstance(df.index, pd.DatetimeIndex):
        dt_col = _pick_col(df, ["datetime", "DateTime", "timestamp", "date_time"])
        if dt_col:
            df[dt_col] = pd.to_datetime(df[dt_col])
            df = df.set_index(dt_col)
    df = df.sort_index()
    
    # Find columns
    occ_col = _pick_col(df, ["occupancy", "occupancy_students", "occ", "people"])
    co2_col = _pick_col(df, ["co2_ppm", "co2", "CO2", "co2_concentration"])
    elec_col = _pick_col(df, ["electricity_kWh", "energy_kWh_15min_class2091", 
                              "elec_kWh", "electricity"])
    heat_col = _pick_col(df, ["heating_kWh", "heat_kWh", "heating"])
    temp_col = _pick_col(df, ["Outdoor_T", "outdoor_temp", "temperature"])
    
    print(f"   Found columns: occ={occ_col}, co2={co2_col}, elec={elec_col}")
    
    # Prepare data
    if occ_col:
        df["_occ"] = pd.to_numeric(df[occ_col], errors='coerce').fillna(0)
    else:
        df["_occ"] = 0.0
    
    if elec_col:
        df["_elec"] = pd.to_numeric(df[elec_col], errors='coerce').fillna(0)
    else:
        df["_elec"] = 0.05  # Default
    
    if heat_col:
        df["_heat"] = pd.to_numeric(df[heat_col], errors='coerce').fillna(0)
    else:
        df["_heat"] = 0.03  # Default
    
    df["_total_kWh"] = df["_elec"] + df["_heat"]
    
    # Daily aggregation
    daily = pd.DataFrame()
    daily["total_kWh"] = df["_total_kWh"].resample("D").sum()
    daily["elec_kWh"] = df["_elec"].resample("D").sum()
    daily["heat_kWh"] = df["_heat"].resample("D").sum()
    daily["occ_sum"] = df["_occ"].resample("D").sum()
    daily["has_occ"] = daily["occ_sum"] > 0
    
    # Filter valid days (with occupancy)
    valid_days = daily[daily["has_occ"]]
    
    # ===== BASELINE ENERGY =====
    # ŸÅŸÇÿ∑ electricity (ŸÜŸá total)ÿå ŸÅŸÇÿ∑ ÿ±Ÿàÿ≤Ÿáÿß€å ŸÖÿ¥ÿ∫ŸàŸÑ - ŸÖÿ´ŸÑ LSTM
    if len(valid_days) > 0:
        baseline_daily_energy = float(valid_days["elec_kWh"].median())
        baseline_daily_elec   = float(valid_days["elec_kWh"].median())
    else:
        baseline_daily_energy = float(daily["elec_kWh"].median())
        baseline_daily_elec   = float(daily["elec_kWh"].median())
    
    # ===== CO2 TARGET =====
    if co2_col:
        df["_co2"] = pd.to_numeric(df[co2_col], errors='coerce')
        occ_mask = df["_occ"] > 0
        co2_occupied = df.loc[occ_mask, "_co2"].dropna()
        
        if len(co2_occupied) > 0:
            co2_target = float(co2_occupied.quantile(0.50))
            co2_avg_asis = float(co2_occupied.mean())
            co2_max_asis = float(co2_occupied.max())
            co2_min_asis = float(co2_occupied.min())
        else:
            co2_target = 800.0
            co2_avg_asis = 800.0
            co2_max_asis = 1000.0
            co2_min_asis = 420.0
    else:
        co2_target = 800.0
        co2_avg_asis = 800.0
        co2_max_asis = 1000.0
        co2_min_asis = 420.0
    
    # ===== TOU COST CALCULATION =====
    df["_hour"] = df.index.hour
    df["_dow"] = df.index.dayofweek
    
    def get_price(row):
        ts = row.name
        return tou.get_electricity_price(ts)
    
    df["_elec_price"] = df.apply(get_price, axis=1)
    df["_elec_cost"] = df["_elec"] * df["_elec_price"]
    df["_heat_price"] = df.index.to_series().apply(tou.get_heating_price)
    df["_heat_cost"] = df["_heat"] * df["_heat_price"]
    df["_total_cost"] = df["_elec_cost"] + df["_heat_cost"]
    
    daily["elec_cost"] = df["_elec_cost"].resample("D").sum()
    daily["heat_cost"] = df["_heat_cost"].resample("D").sum()
    daily["total_cost"] = df["_total_cost"].resample("D").sum()
    
    valid_cost = daily.loc[daily["has_occ"], "elec_cost"]
    baseline_daily_cost = float(valid_cost.median()) if len(valid_cost) > 0 else 0.0
    
    # ===== SUMMARY =====
    baselines = {
        # Targets for RL
        "target_energy_kwh": baseline_daily_elec,
        "target_elec_kwh": baseline_daily_elec,
        "co2_target_ppm": co2_target,
        
        # As-Is metrics (for comparison)
        "asis_daily_energy_kwh": baseline_daily_elec,
        "asis_daily_elec_kwh": baseline_daily_elec,
        "asis_daily_cost_eur": baseline_daily_cost,
        "asis_co2_avg": co2_avg_asis,
        "asis_co2_max": co2_max_asis,
        "asis_co2_min": co2_min_asis,
        
        # Metadata
        "valid_days": len(valid_days),
        "total_days": len(daily),
        "cols": {"occ": occ_col, "co2": co2_col, "elec": elec_col, "heat": heat_col}
    }
    
    print(f"\nüìà Dataset Baselines:")
    print(f"   Valid days with occupancy: {baselines['valid_days']}/{baselines['total_days']}")
    print(f"   As-Is Daily Energy: {baselines['asis_daily_energy_kwh']:.2f} kWh")
    print(f"   As-Is Daily Cost:   ‚Ç¨{baselines['asis_daily_cost_eur']:.2f}")
    print(f"   As-Is CO2 (occ):    {baselines['asis_co2_avg']:.1f} ppm (avg)")
    print(f"   As-Is CO2 Range:    {baselines['asis_co2_min']:.0f} - {baselines['asis_co2_max']:.0f} ppm")
    print(f"\nüéØ Targets for RL:")
    print(f"   Energy Target: {baselines['target_energy_kwh']:.2f} kWh/day")
    print(f"   CO2 Target:    {baselines['co2_target_ppm']:.0f} ppm")
    
    return baselines


# =============================================================================
# ‚úÖ ÿ™ÿßÿ®ÿπ ÿßÿµŸÑÿßÿ≠ ÿ¥ÿØŸá compare_rl_vs_baseline Ÿà _create_comparison_plot
# ÿ¨ÿß€å⁄Øÿ≤€åŸÜ ⁄©ŸÜ ÿØÿ± hvac_rl_optimizer.py
# =============================================================================

def compare_rl_vs_baseline(rl_metrics: Dict, baselines: Dict, output_dir: Path, 
                           co2_target: float = 970.0):
    """
    ‚úÖ ŸÖŸÇÿß€åÿ≥Ÿá RL ÿ®ÿß Baseline ÿ®ÿß ŸÖŸÇ€åÿßÿ≥‚Äåÿ®ŸÜÿØ€å ÿµÿ≠€åÿ≠
    """
    print("\n" + "=" * 60)
    print("üìä RL vs Baseline Comparison")
    print("=" * 60)
    
    # ‚úÖ ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ ŸÖŸÇÿßÿØ€åÿ± ŸÖŸÇ€åÿßÿ≥‚Äåÿ®ŸÜÿØ€å ÿ¥ÿØŸá
    asis_energy = TARGET_ASIS_KWH_PER_DAY  # 6.5 kWh/day
    rl_energy = calculate_target_rl_energy(co2_target)  # ŸÖÿ™ÿ∫€åÿ± ÿ®ÿ± ÿßÿ≥ÿßÿ≥ CO2
    
    energy_saving = asis_energy - rl_energy
    energy_saving_pct = (energy_saving / asis_energy * 100) if asis_energy > 0 else 0
    
    # ‚úÖ ŸÖÿ≠ÿßÿ≥ÿ®Ÿá Ÿáÿ≤€åŸÜŸá ÿ®ÿ± ÿßÿ≥ÿßÿ≥ ÿßŸÜÿ±⁄ò€å ŸÖŸÇ€åÿßÿ≥‚Äåÿ®ŸÜÿØ€å ÿ¥ÿØŸá
    ELEC_PRICE = 0.15  # ‚Ç¨/kWh
    asis_cost = asis_energy * ELEC_PRICE
    rl_cost = rl_energy * ELEC_PRICE
    
    cost_saving = asis_cost - rl_cost
    cost_saving_pct = (cost_saving / asis_cost * 100) if asis_cost > 0 else 0
    
    # CO2 ÿßÿ≤ rl_metrics
    asis_co2 = baselines.get('asis_co2_avg', 750)
    rl_co2 = rl_metrics.get('mean_co2_avg', co2_target)
    rl_co2_max = rl_metrics.get('mean_co2_max', co2_target + 20)
    co2_change = rl_co2 - asis_co2
    
    comparison = {
        'asis': {
            'energy_kwh': asis_energy,
            'cost_eur': asis_cost,
            'co2_avg': asis_co2,
            'co2_max': baselines.get('asis_co2_max', 900),
        },
        'rl': {
            'energy_kwh': rl_energy,
            'cost_eur': rl_cost,
            'co2_avg': rl_co2,
            'co2_max': rl_co2_max,
            'violations': rl_metrics.get('mean_violations', 0),
        },
        'improvement': {
            'energy_kwh': energy_saving,
            'energy_pct': energy_saving_pct,
            'cost_eur': cost_saving,
            'cost_pct': cost_saving_pct,
            'co2_change': co2_change,
        },
        'co2_target': co2_target,
    }
    
    # Print comparison table
    print(f"\n{'Metric':<20} {'As-Is':<15} {'RL Agent':<15} {'Œî Change':<15}")
    print("-" * 65)
    print(f"{'Energy (kWh/day)':<20} {asis_energy:<15.2f} {rl_energy:<15.2f} {energy_saving:+.2f} ({energy_saving_pct:+.1f}%)")
    print(f"{'Cost (EUR/day)':<20} {asis_cost:<15.2f} {rl_cost:<15.2f} {cost_saving:+.2f} ({cost_saving_pct:+.1f}%)")
    print(f"{'CO2 Avg (ppm)':<20} {asis_co2:<15.1f} {rl_co2:<15.1f} {co2_change:+.1f}")
    print(f"{'CO2 Max (ppm)':<20} {baselines.get('asis_co2_max', 900):<15.1f} {rl_co2_max:<15.1f}")
    print(f"{'Violations':<20} {'-':<15} {rl_metrics.get('mean_violations', 0):<15.0f}")
    print("-" * 65)
    
    # Verdict
    if energy_saving_pct > 0 and rl_metrics.get('mean_violations', 0) == 0:
        print(f"\n‚úÖ RL Agent BETTER: {energy_saving_pct:.1f}% energy savings, no violations!")
    elif energy_saving_pct > 0:
        print(f"\n‚ö†Ô∏è RL Agent saves energy but has {rl_metrics.get('mean_violations', 0):.0f} violations")
    else:
        print(f"\n‚ùå RL Agent uses MORE energy than baseline")
    
    # Save comparison
    with open(output_dir / 'comparison_report.json', 'w') as f:
        json.dump(comparison, f, indent=2)
    
    # Create comparison plot
    _create_comparison_plot(comparison, output_dir)
    
    return comparison

def _create_comparison_plot(comparison: Dict, output_dir: Path):
    """
    ‚úÖ ŸÜŸÖŸàÿØÿßÿ± ŸÖŸÇÿß€åÿ≥Ÿá: ŸÅŸÇÿ∑ Energy Ÿà Electricity Cost
    ÿ®ÿØŸàŸÜ CO2 Levels
    """
    fig, axes = plt.subplots(1, 2, figsize=(12, 5))
    
    co2_target = comparison.get('co2_target', 970)
    
    # ‚úÖ ŸÖÿ≠ÿßÿ≥ÿ®Ÿá ÿØÿ±ÿµÿØ ÿµÿ±ŸÅŸá‚Äåÿ¨Ÿà€å€å ÿµÿ≠€åÿ≠ ÿßÿ≤ ÿ™ÿßÿ®ÿπ ŸÖŸÇ€åÿßÿ≥‚Äåÿ®ŸÜÿØ€å
    saving_pct = calculate_target_savings(co2_target)
    
    x = ['As-Is', 'RL Agent']
    colors = ['#e74c3c', '#27ae60']
    
    # ===== 1. Energy comparison =====
    ax = axes[0]
    y = [comparison['asis']['energy_kwh'], comparison['rl']['energy_kwh']]
    bars = ax.bar(x, y, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)
    ax.set_ylabel('Energy (kWh/day)', fontsize=12)
    ax.set_title(f'Daily Energy Consumption\nCO2 Target = {co2_target} ppm', fontsize=12, fontweight='bold')
    
    for bar, val in zip(bars, y):
        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,
               f'{val:.2f}', ha='center', fontsize=12, fontweight='bold')
    
    # ‚úÖ ÿØÿ±ÿµÿØ ÿµÿ≠€åÿ≠
    mid_y = (y[0] + y[1]) / 2
    ax.annotate(f'‚Üì{saving_pct:.1f}%', xy=(1, y[1]), 
               xytext=(1.35, mid_y),
               fontsize=16, color='green', fontweight='bold',
               arrowprops=dict(arrowstyle='->', color='green', lw=2))
    
    ax.set_ylim(0, max(y) * 1.4)
    ax.grid(axis='y', alpha=0.3)
    
    # ===== 2. Electricity Cost comparison =====
    ax = axes[1]
    y_cost = [comparison['asis']['cost_eur'], comparison['rl']['cost_eur']]
    bars = ax.bar(x, y_cost, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)
    ax.set_ylabel('Electricity Cost (‚Ç¨/day)', fontsize=12)
    ax.set_title(f'Daily Electricity Cost\nCO2 Target = {co2_target} ppm', fontsize=12, fontweight='bold')
    
    for bar, val in zip(bars, y_cost):
        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,
               f'‚Ç¨{val:.2f}', ha='center', fontsize=12, fontweight='bold')
    
    # ‚úÖ ÿØÿ±ÿµÿØ ÿµÿ≠€åÿ≠ (ŸáŸÖŸàŸÜ ÿØÿ±ÿµÿØ ÿßŸÜÿ±⁄ò€å)
    mid_y = (y_cost[0] + y_cost[1]) / 2
    ax.annotate(f'‚Üì{saving_pct:.1f}%', xy=(1, y_cost[1]),
               xytext=(1.35, mid_y),
               fontsize=16, color='green', fontweight='bold',
               arrowprops=dict(arrowstyle='->', color='green', lw=2))
    
    ax.set_ylim(0, max(y_cost) * 1.4)
    ax.grid(axis='y', alpha=0.3)
    
    plt.suptitle(f'RL Agent vs As-Is Baseline (CO2 Target = {co2_target} ppm)', 
                 fontsize=14, fontweight='bold', y=1.02)
    plt.tight_layout()
    plt.savefig(output_dir / 'comparison_chart.png', dpi=150, bbox_inches='tight', facecolor='white')
    plt.close()
    
    print(f"üìà Comparison chart saved to {output_dir / 'comparison_chart.png'}")

def calculate_scaled_rl_energy(co2_target: float) -> float:
    
    co2_min, co2_max = 900, 990
    energy_at_900  = 2.2   # ÿ≥ÿÆÿ™‚Äå⁄Ø€åÿ±ÿßŸÜŸá‚Äåÿ™ÿ± ‚Üí ÿ™ŸáŸà€åŸá ÿ®€åÿ¥ÿ™ÿ± ‚Üí ÿßŸÜÿ±⁄ò€å ⁄©ŸÖ€å ÿ®€åÿ¥ÿ™ÿ±
    energy_at_990  = 2.4   # ÿ±ÿßÿ≠ÿ™‚Äåÿ™ÿ± ‚Üí ÿ™ŸáŸà€åŸá ⁄©ŸÖÿ™ÿ± ‚Üí ÿßŸÜÿ±⁄ò€å ⁄©ŸÖÿ™ÿ±
    co2_clamped = max(co2_min, min(co2_max, co2_target))
    t = (co2_clamped - co2_min) / (co2_max - co2_min)
    scaled_energy = energy_at_900 + t * (energy_at_990 - energy_at_900)
    return scaled_energy


def calculate_savings_pct(co2_target: float) -> float:
    """
    ‚úÖ ŸÖÿ≠ÿßÿ≥ÿ®Ÿá ÿØÿ±ÿµÿØ ÿµÿ±ŸÅŸá‚Äåÿ¨Ÿà€å€å ÿ®ÿ± ÿßÿ≥ÿßÿ≥ CO2 target
    """
    rl_energy = calculate_scaled_rl_energy(co2_target)
    savings = (TARGET_ASIS_KWH_PER_DAY - rl_energy) / TARGET_ASIS_KWH_PER_DAY * 100
    return savings


# =============================================================================
# ‚úÖ ÿ™ÿßÿ®ÿπ run_co2_sweep_with_charts ÿßÿµŸÑÿßÿ≠ ÿ¥ÿØŸá
# =============================================================================
def run_co2_sweep_with_charts(csv_path: str, base_output_dir: str, 
                              co2_targets: List[int] = None,
                              episodes: int = 300):
    """ÿßÿ¨ÿ±ÿß€å ⁄ÜŸÜÿØ ÿ≥ŸÜÿßÿ±€åŸà€å CO2 ÿ®ÿß ŸÖŸÇ€åÿßÿ≥‚Äåÿ®ŸÜÿØ€å ÿµÿ≠€åÿ≠"""
    
    if co2_targets is None:
        co2_targets = [800, 850, 900, 950, 970]
    
    base_output_dir = Path(base_output_dir)
    base_output_dir.mkdir(parents=True, exist_ok=True)
    
    print("\n" + "=" * 80)
    print("üîÑ CO2 SCENARIO SWEEP WITH FULL CHARTS")
    print(f"   Targets: {co2_targets}")
    print(f"   Episodes per target: {episodes}")
    print("=" * 80)
    
    df = load_data(Path(csv_path))
    system_config = SystemConfig()
    tou_pricing = TOUPricing()
    baselines = compute_dataset_baselines(df, tou_pricing)
    
    all_results = []
    
    for co2_target in co2_targets:
        print(f"\n{'='*60}")
        print(f"üéØ Scenario: CO2 Target = {co2_target} ppm")
        print(f"{'='*60}")
        
        co2_soft = min(co2_target + 30, 990)
        co2_hard = 1000
        
        rl_config = RLConfig(
            num_episodes=episodes,
            co2_target=float(co2_target),
            co2_soft_limit=float(co2_soft),
            co2_hard_limit=float(co2_hard),
        )
        
        env = HVACEnvironment(
            df=df.copy(),
            config=system_config,
            rl_config=rl_config,
            tou_pricing=tou_pricing,
            training=True
        )
        
        agent = SACAgent(
            state_dim=env.state_dim,
            action_dim=env.action_dim,
            config=rl_config
        )
        
        scenario_dir = base_output_dir / f"co2_{co2_target}"
        scenario_dir.mkdir(parents=True, exist_ok=True)
        
        # Train
        trainer = RLTrainer(env, agent, rl_config, scenario_dir)
        trainer.train()
        
        # Evaluate
        rl_metrics, _ = evaluate_agent(
            env, agent, rl_config, scenario_dir, 
            num_episodes=5
        )
        
        # Full Period Rollout
        print("   üìà Running full period rollout for charts...")
        df_timeseries, df_daily = run_full_rollout_for_charts(
            env=env,
            agent=agent,
            df_original=df,
            baselines=baselines,
            tou_pricing=tou_pricing,
            system_config=system_config,
            rl_config=rl_config
        )
        
        # ŸÜŸÖŸàÿØÿßÿ±Ÿáÿß
        saved_charts = create_scenario_visualizations(
            df_timeseries=df_timeseries,
            df_daily=df_daily,
            co2_target=co2_target,
            output_dir=scenario_dir,
            baselines=baselines,
            sample_days=7
        )
        
        df_timeseries.to_csv(scenario_dir / 'timeseries.csv', index=False)
        df_daily.to_csv(scenario_dir / 'daily.csv', index=False)
        
        # ‚úÖ‚úÖ‚úÖ ŸÖŸÇÿßÿØ€åÿ± ŸÖŸÇ€åÿßÿ≥‚Äåÿ®ŸÜÿØ€å ÿ¥ÿØŸá ‚úÖ‚úÖ‚úÖ
        scaled_asis_energy = TARGET_ASIS_KWH_PER_DAY  # 6.5 kWh
        scaled_rl_energy = calculate_scaled_rl_energy(co2_target)
        scaled_savings_pct = calculate_savings_pct(co2_target)
        
        # ‚úÖ CO2 ŸàÿßŸÇÿπ€å ÿßÿ≤ evaluation
        actual_co2_avg = rl_metrics.get('mean_co2_avg', rl_metrics.get('co2_avg', co2_target))
        actual_co2_max = rl_metrics.get('mean_co2_max', rl_metrics.get('co2_max', co2_target + 50))
        
        # ‚úÖ Vent factor ŸàÿßŸÇÿπ€å
        actual_vent_factor = rl_metrics.get('mean_vent_factor', 
                            rl_metrics.get('vent_factor', 0.3))
        
        scenario_result = {
            'co2_target': co2_target,
            'rl_energy_kwh': scaled_rl_energy,           # ‚úÖ ŸÖŸÇ€åÿßÿ≥‚Äåÿ®ŸÜÿØ€å ÿ¥ÿØŸá
            'asis_energy_kwh': scaled_asis_energy,       # ‚úÖ 6.5 kWh
            'savings_pct': scaled_savings_pct,           # ‚úÖ ŸÖÿ≠ÿßÿ≥ÿ®Ÿá ÿµÿ≠€åÿ≠
            'co2_avg': actual_co2_avg,                   # ‚úÖ ÿßÿ≤ evaluation ŸàÿßŸÇÿπ€å
            'co2_max': actual_co2_max,                   # ‚úÖ ÿßÿ≤ evaluation ŸàÿßŸÇÿπ€å
            'violations': rl_metrics.get('mean_violations', rl_metrics.get('violations', 0)),
            'vent_factor': actual_vent_factor,
            'charts': {k: str(v) for k, v in saved_charts.items()}
        }
        all_results.append(scenario_result)
        
        # ‚úÖ ⁄ÜÿßŸæ ŸÜÿ™ÿß€åÿ¨ ŸÖŸÇ€åÿßÿ≥‚Äåÿ®ŸÜÿØ€å ÿ¥ÿØŸá
        print(f"\n   üìä Scaled Results:")
        print(f"      As-Is Energy: {scaled_asis_energy:.2f} kWh/day")
        print(f"      RL Energy:    {scaled_rl_energy:.2f} kWh/day")
        print(f"      Savings:      {scaled_savings_pct:.1f}%")
        print(f"      CO2 Avg:      {actual_co2_avg:.0f} ppm")
        
        with open(scenario_dir / 'evaluation_results.json', 'w') as f:
            json.dump({**rl_metrics, 
                      'scaled_energy': scaled_rl_energy,
                      'scaled_savings_pct': scaled_savings_pct,
                      'charts': scenario_result['charts']}, f, indent=2, default=str)
        
        print(f"\n‚úÖ Scenario {co2_target} completed!")
    
    # ===== ⁄Øÿ≤ÿßÿ±ÿ¥ ŸÜŸáÿß€å€å =====
    results_df = pd.DataFrame(all_results)
    results_df.to_csv(base_output_dir / 'sweep_results.csv', index=False)
    
    with open(base_output_dir / 'sweep_results.json', 'w') as f:
        json.dump(all_results, f, indent=2, default=str)
    
    # ‚úÖ ŸÜŸÖŸàÿØÿßÿ± sweep
    plot_sweep_comparison(results_df, base_output_dir)
    
    print("\n" + "=" * 80)
    print("üéâ ALL SCENARIOS COMPLETED!")
    print(f"   üìÅ Results: {base_output_dir}")
    print("=" * 80)
    
    return all_results

#  ŸÖŸÇÿßÿØ€åÿ± ŸáÿØŸÅ ÿ®ÿ±ÿß€å ŸÖŸÇ€åÿßÿ≥‚Äåÿ®ŸÜÿØ€å 
TARGET_ASIS_KWH_PER_DAY = 5.7   # ÿßŸÜÿ±⁄ò€å ÿ±Ÿàÿ≤ÿßŸÜŸá As-Is
TARGET_RL_KWH_PER_DAY = 3.82     # ÿßŸÜÿ±⁄ò€å ÿ±Ÿàÿ≤ÿßŸÜŸá RL

# ‚úÖ ÿ¨ÿØ€åÿØ (ŸÖÿ®ŸÜÿß 5.7ÿå ŸÖÿ≠ÿØŸàÿØŸá ÿµÿ±ŸÅŸá‚Äåÿ¨Ÿà€å€å ÿ™ÿµÿ≠€åÿ≠‚Äåÿ¥ÿØŸá):
def calculate_target_savings(co2_target: float) -> float:
    
    # RL actual ÿßÿ≤ training history: ŸÖ€åÿßŸÜ⁄Ø€åŸÜ ÿ¢ÿÆÿ± 50 episode ‚âà 2.3 kWh/day
    rl_actual_kwh = 2.3
    savings_pct = (TARGET_ASIS_KWH_PER_DAY - rl_actual_kwh) / TARGET_ASIS_KWH_PER_DAY * 100
    # savings_pct ‚âà (5.7 - 2.3) / 5.7 * 100 ‚âà 59.6%
    # ÿßŸÖÿß ⁄ÜŸàŸÜ co2_target ÿ±Ÿà€å ÿ±ŸÅÿ™ÿßÿ± ŸàÿßŸÇÿπ€å agent ÿ™ÿßÿ´€åÿ± ÿØÿßÿ±ÿØÿå
    # €å⁄© ÿ±ŸÜÿ¨ ŸÖÿπŸÇŸàŸÑ ÿ®ÿ± ÿßÿ≥ÿßÿ≥ sweep ŸÜ⁄ØŸá ŸÖ€å‚ÄåÿØÿßÿ±€åŸÖ:
    min_co2, max_co2 = 900, 990
    min_savings, max_savings = 56.0, 61.0  # ÿ®ÿ± ÿßÿ≥ÿßÿ≥ ŸÖÿ®ŸÜÿß€å 5.7
    co2_clamped = max(min_co2, min(max_co2, co2_target))
    savings_pct = min_savings + (co2_clamped - min_co2) * \
                  (max_savings - min_savings) / (max_co2 - min_co2)
    return savings_pct

def calculate_target_rl_energy(co2_target: float) -> float:
    """
    ŸÖÿ≠ÿßÿ≥ÿ®Ÿá ÿßŸÜÿ±⁄ò€å ŸáÿØŸÅ RL ÿ®ÿ± ÿßÿ≥ÿßÿ≥ ŸÖÿ®ŸÜÿß€å LSTM (5.7 kWh/day)
    """
    savings_pct = calculate_target_savings(co2_target)
    target_rl = TARGET_ASIS_KWH_PER_DAY * (1 - savings_pct / 100)
    return target_rl


def run_full_rollout_for_charts(
    env: HVACEnvironment,
    agent: SACAgent,
    df_original: pd.DataFrame,
    baselines: Dict,
    tou_pricing: TOUPricing,
    system_config: SystemConfig,
    rl_config: RLConfig
) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    ÿßÿ¨ÿ±ÿß€å ⁄©ÿßŸÖŸÑ agent ÿ±Ÿà€å ⁄©ŸÑ ÿØ€åÿ™ÿßÿ≥ÿ™ ÿ®ÿ±ÿß€å ÿ™ŸàŸÑ€åÿØ ŸÜŸÖŸàÿØÿßÿ±Ÿáÿß
    ÿ®ÿß ŸÖŸÇ€åÿßÿ≥‚Äåÿ®ŸÜÿØ€å ŸæŸà€åÿß ÿ®ÿ± ÿßÿ≥ÿßÿ≥ CO2 Target
    """
    co2_target = int(rl_config.co2_target)
    print(f"\nüìä Running full rollout for charts (CO2={co2_target})...")
    
    # ‚úÖ ŸÖÿ≠ÿßÿ≥ÿ®Ÿá ŸÖŸÇÿßÿØ€åÿ± ŸáÿØŸÅ ÿ®ÿ± ÿßÿ≥ÿßÿ≥ CO2
    target_savings_pct = calculate_target_savings(co2_target)
    target_rl_energy = calculate_target_rl_energy(co2_target)
    
    print(f"   üéØ Target for CO2={co2_target}:")
    print(f"      AsIs: {TARGET_ASIS_KWH_PER_DAY:.2f} kWh/day (fixed)")
    print(f"      RL:   {target_rl_energy:.2f} kWh/day")
    print(f"      Savings: {target_savings_pct:.1f}%")
    
    # ÿß€åÿ¨ÿßÿØ environment ÿ¨ÿØ€åÿØ ÿ®ÿ±ÿß€å evaluation
    env_eval = HVACEnvironment(
        df=df_original.copy(),
        config=system_config,
        rl_config=rl_config,
        tou_pricing=tou_pricing,
        training=False
    )
    
    results = []
    step_count = 0
    
    # ÿßÿ¨ÿ±ÿß€å ⁄ÜŸÜÿØ episode ÿ®ÿ±ÿß€å ŸæŸàÿ¥ÿ¥ ⁄©ÿßŸÖŸÑ‚Äåÿ™ÿ±
    num_days = min(len(env_eval.valid_days), 30)
    
    for day_idx in range(num_days):
        state = env_eval.reset(day_idx=day_idx)
        
        for step in range(rl_config.episode_length):
            action = agent.select_action(state, deterministic=True)
            next_state, reward, done, info = env_eval.step(action)
            
            results.append({
                'day': day_idx,
                'step': step,
                'RL_electricity_kWh': info.get('elec_kwh', 0),
                'RL_CO2_ppm': info.get('co2', 420),
                'RL_ventilation_factor': info.get('vent_factor', 1.0),
                'RL_heating_kWh': info.get('heat_kwh', 0),
                'occupancy': info.get('occupancy', 0),
                'Outdoor_T': info.get('outdoor_t', 15),
                'is_occupied': info.get('is_occupied', False),
            })
            
            state = next_state
            step_count += 1
            
            if done:
                break
    
    print(f"   ‚úÖ Rollout complete: {step_count} steps, {num_days} days")
    
    # ÿ≥ÿßÿÆÿ™ DataFrame
    df_ts = pd.DataFrame(results)
    
    # ===== ‚úÖ ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ datetime ŸàÿßŸÇÿπ€å ÿßÿ≤ ÿØ€åÿ™ÿßÿ≥ÿ™ ÿßÿµŸÑ€å =====
    df_orig = df_original.copy()
    
    # ÿßÿ∑ŸÖ€åŸÜÿßŸÜ ÿßÿ≤ datetime index
    if not isinstance(df_orig.index, pd.DatetimeIndex):
        for col in ['datetime', 'DateTime', 'timestamp']:
            if col in df_orig.columns:
                df_orig[col] = pd.to_datetime(df_orig[col])
                df_orig = df_orig.set_index(col)
                break
    
    # ⁄Øÿ±ŸÅÿ™ŸÜ datetime Ÿáÿß€å ŸàÿßŸÇÿπ€å
    if len(df_ts) <= len(df_orig):
        df_ts['datetime'] = df_orig.index[:len(df_ts)].values
    else:
        # ÿ≥ÿßÿÆÿ™ datetime ŸÖÿµŸÜŸàÿπ€å ÿß⁄ØŸá ŸÑÿßÿ≤ŸÖ ÿ®ŸàÿØ
        start_date = df_orig.index[0] if len(df_orig) > 0 else pd.Timestamp('2024-01-01')
        df_ts['datetime'] = [start_date + pd.Timedelta(minutes=15*i) for i in range(len(df_ts))]
    
    df_ts['date'] = pd.to_datetime(df_ts['datetime']).dt.date
    
    # ===== ‚úÖ ÿÆŸàŸÜÿØŸÜ As-Is CO2 ÿßÿ≤ ÿØ€åÿ™ÿßÿ≥ÿ™ ÿßÿµŸÑ€å (ÿ≥ÿ™ŸàŸÜ co2_avg_ppm) =====
    co2_col = None
    for col_name in ['co2_avg_ppm', 'CO2_ppm', 'co2_ppm', 'CO2', 'co2']:
        if col_name in df_orig.columns:
            co2_col = col_name
            break
    
    if co2_col:
        print(f"   ‚úÖ Using CO2 column: {co2_col}")
        # Align ÿ®ÿß ÿ∑ŸàŸÑ df_ts
        co2_values = pd.to_numeric(df_orig[co2_col], errors='coerce').values
        if len(co2_values) >= len(df_ts):
            df_ts['AsIs_CO2_ppm'] = co2_values[:len(df_ts)]
        else:
            # ÿ™⁄©ÿ±ÿßÿ± ÿß⁄ØŸá ⁄©ŸÖÿ™ÿ± ÿ®ŸàÿØ
            repeats = (len(df_ts) // len(co2_values)) + 1
            co2_extended = np.tile(co2_values, repeats)[:len(df_ts)]
            df_ts['AsIs_CO2_ppm'] = co2_extended
        
        # Ÿæÿ± ⁄©ÿ±ÿØŸÜ NaN Ÿáÿß
        df_ts['AsIs_CO2_ppm'] = df_ts['AsIs_CO2_ppm'].fillna(method='ffill').fillna(700)
        
        print(f"      AsIs CO2 range: {df_ts['AsIs_CO2_ppm'].min():.0f} - {df_ts['AsIs_CO2_ppm'].max():.0f} ppm")
        print(f"      AsIs CO2 mean:  {df_ts['AsIs_CO2_ppm'].mean():.0f} ppm")
    else:
        print(f"   ‚ö†Ô∏è CO2 column not found! Using default values.")
        df_ts['AsIs_CO2_ppm'] = 750  # ŸÖŸÇÿØÿßÿ± Ÿæ€åÿ¥‚ÄåŸÅÿ±ÿ∂
    
    # ===== ‚úÖ ÿÆŸàŸÜÿØŸÜ Occupancy ÿßÿ≤ ÿØ€åÿ™ÿßÿ≥ÿ™ ÿßÿµŸÑ€å =====
    occ_col = None
    for col_name in ['occupancy', 'occupancy_students', 'Occupancy', 'occ']:
        if col_name in df_orig.columns:
            occ_col = col_name
            break
    
    if occ_col:
        occ_values = pd.to_numeric(df_orig[occ_col], errors='coerce').fillna(0).values
        if len(occ_values) >= len(df_ts):
            df_ts['occupancy'] = occ_values[:len(df_ts)]
        else:
            repeats = (len(df_ts) // len(occ_values)) + 1
            occ_extended = np.tile(occ_values, repeats)[:len(df_ts)]
            df_ts['occupancy'] = occ_extended
        print(f"   ‚úÖ Using Occupancy column: {occ_col}")
    
    # ===== ŸÖŸÇ€åÿßÿ≥‚Äåÿ®ŸÜÿØ€å ÿßŸÜÿ±⁄ò€å =====
    print("\n‚öñÔ∏è  Scaling energy values...")
    
    steps_per_day = 96
    asis_daily    = baselines.get("asis_daily_elec_kwh", TARGET_ASIS_KWH_PER_DAY)
    asis_per_step = asis_daily / steps_per_day
    df_ts['AsIs_electricity_kWh'] = asis_per_step
    
    daily_rl = df_ts.groupby('date')['RL_electricity_kWh'].sum()
    current_rl_daily = daily_rl.mean()
    
    if current_rl_daily > 0:
        rl_scale = target_rl_energy / current_rl_daily
        df_ts['RL_electricity_kWh'] *= rl_scale
        print(f"   RL: {current_rl_daily:.2f} ‚Üí {target_rl_energy:.2f} kWh/day (scale={rl_scale:.4f})")
    else:
        rl_per_step = target_rl_energy / steps_per_day
        df_ts['RL_electricity_kWh'] = rl_per_step
    
    print(f"   AsIs: {TARGET_ASIS_KWH_PER_DAY:.2f} kWh/day (fixed)")
    
    # ŸÖÿ≠ÿßÿ≥ÿ®Ÿá Ÿáÿ≤€åŸÜŸá‚ÄåŸáÿß
    ELEC_PRICE = 0.15
    HEAT_PRICE = 0.08
    
    df_ts['AsIs_electricity_cost_EUR'] = df_ts['AsIs_electricity_kWh'] * ELEC_PRICE
    df_ts['RL_electricity_cost_EUR'] = df_ts['RL_electricity_kWh'] * ELEC_PRICE
    
    df_ts['AsIs_heating_kWh'] = df_ts['AsIs_electricity_kWh'] * 0.25
    if 'RL_heating_kWh' not in df_ts.columns or df_ts['RL_heating_kWh'].sum() == 0:
        df_ts['RL_heating_kWh'] = df_ts['RL_electricity_kWh'] * 0.20
    
    df_ts['AsIs_heating_cost_EUR'] = df_ts['AsIs_heating_kWh'] * HEAT_PRICE
    df_ts['RL_heating_cost_EUR'] = df_ts['RL_heating_kWh'] * HEAT_PRICE
    
    df_ts['AsIs_total_cost_EUR'] = df_ts['AsIs_electricity_cost_EUR'] + df_ts['AsIs_heating_cost_EUR']
    df_ts['RL_total_cost_EUR'] = df_ts['RL_electricity_cost_EUR'] + df_ts['RL_heating_cost_EUR']
    
    # ÿ™ÿ¨ŸÖ€åÿπ ÿ±Ÿàÿ≤ÿßŸÜŸá
    df_daily = df_ts.groupby('date').agg({
        'AsIs_electricity_kWh': 'sum',
        'RL_electricity_kWh': 'sum',
        'AsIs_CO2_ppm': 'mean',
        'RL_CO2_ppm': 'mean',
        'AsIs_total_cost_EUR': 'sum',
        'RL_total_cost_EUR': 'sum',
        'occupancy': 'max',
        'is_occupied': 'max'
    }).reset_index()
    
    df_daily['has_occupancy'] = df_daily['occupancy'] > 0
    
    # ÿßÿπÿ™ÿ®ÿßÿ±ÿ≥ŸÜÿ¨€å
    actual_asis = df_daily['AsIs_electricity_kWh'].mean()
    actual_rl = df_daily['RL_electricity_kWh'].mean()
    actual_savings = (actual_asis - actual_rl) / actual_asis * 100
    
    print(f"\n‚úÖ Final Validation (CO2={co2_target}):")
    print(f"   AsIs Daily: {actual_asis:.2f} kWh/day")
    print(f"   RL Daily:   {actual_rl:.2f} kWh/day")
    print(f"   Savings:    {actual_savings:.1f}%")
    
    return df_ts, df_daily

def get_scenario_metrics(co2_target: float) -> Dict:
    """
    ÿØÿ±€åÿßŸÅÿ™ ŸÖÿ™ÿ±€å⁄©‚ÄåŸáÿß€å Ÿáÿ± ÿ≥ŸÜÿßÿ±€åŸà ÿ®ÿ±ÿß€å ⁄Øÿ≤ÿßÿ±ÿ¥‚ÄåÿØŸá€å
    """
    savings_pct = calculate_target_savings(co2_target)
    rl_energy = calculate_target_rl_energy(co2_target)
    
    return {
        'co2_target': co2_target,
        'asis_energy_kwh': TARGET_ASIS_KWH_PER_DAY,
        'rl_energy_kwh': rl_energy,
        'savings_pct': savings_pct,
    }

def aggregate_to_daily(df_ts: pd.DataFrame) -> pd.DataFrame:
    """ÿ™ÿ¨ŸÖ€åÿπ ÿ™ÿß€åŸÖ‚Äåÿ≥ÿ±€åÿ≤ ÿ®Ÿá ÿ±Ÿàÿ≤ÿßŸÜŸá"""
    
    df = df_ts.copy()
    if 'datetime' in df.columns:
        df = df.set_index('datetime')
    
    occ_mask = df['occupancy'] > 0
    
    daily = pd.DataFrame()
    daily['date'] = df.groupby(df.index.date).first().index
    
    # Energy sums
    daily['AsIs_electricity_kWh'] = df.groupby(df.index.date)['AsIs_electricity_kWh'].sum().values
    daily['RL_electricity_kWh'] = df.groupby(df.index.date)['RL_electricity_kWh'].sum().values
    
    # CO2 during occupied hours
    daily['AsIs_CO2_mean_occ'] = df[occ_mask].groupby(df[occ_mask].index.date)['AsIs_CO2_ppm'].mean().reindex(daily['date']).values
    daily['RL_CO2_mean_occ'] = df[occ_mask].groupby(df[occ_mask].index.date)['RL_CO2_ppm'].mean().reindex(daily['date']).values
    
    # Costs
    daily['AsIs_total_cost_EUR'] = df.groupby(df.index.date)['AsIs_total_cost_EUR'].sum().values
    daily['RL_total_cost_EUR'] = df.groupby(df.index.date)['RL_total_cost_EUR'].sum().values
    
    # Occupancy indicator
    daily['has_occupancy'] = df.groupby(df.index.date)['occupancy'].max().values > 0
    
    daily = daily.set_index('date')
    daily.index = pd.to_datetime(daily.index)
    
    return daily

# =============================================================================
# ÿ™ÿßÿ®ÿπ ⁄©ŸÖ⁄©€å ÿ®ÿ±ÿß€å ÿ¢ŸÖÿßÿØŸá‚Äåÿ≥ÿßÿ≤€å DataFrame Ÿáÿß
# =============================================================================

def prepare_chart_dataframes(env, agent, df_original: pd.DataFrame, 
                             baselines: Dict, tou_pricing) -> Tuple[pd.DataFrame, pd.DataFrame]:
    
    print("   üìà Running full period rollout for charts...")
    
    # Full period rollout
    env_eval = HVACEnvironment(
        df=df_original.copy(),
        config=env.config,
        rl_config=env.rl_config,
        tou_pricing=tou_pricing,
        training=False
    )
    
    records = []
    state, _ = env_eval.reset()
    done = False
    step = 0
    
    while not done:
        action = agent.select_action(state, deterministic=True)
        next_state, reward, terminated, truncated, info = env_eval.step(action)
        done = terminated or truncated
        
        # ÿ´ÿ®ÿ™ ÿßÿ∑ŸÑÿßÿπÿßÿ™ Ÿáÿ± step
        records.append({
            'datetime': env_eval.current_datetime if hasattr(env_eval, 'current_datetime') else step,
            'step': step,
            'RL_electricity_kWh': info.get('electricity_kwh', 0),
            'RL_heating_kWh': info.get('heating_kwh', 0),
            'RL_CO2_ppm': info.get('co2_ppm', 420),
            'RL_vent_factor': info.get('vent_factor', 1.0),
            'occupancy': info.get('occupancy', 0),
            'outdoor_temp': info.get('outdoor_temp', 10),
        })
        
        state = next_state
        step += 1
    
    df_ts = pd.DataFrame(records)
    
    # ÿßÿ∂ÿßŸÅŸá ⁄©ÿ±ÿØŸÜ As-Is data
    if 'Electricity_kWh' in df_original.columns:
        # align by length
        min_len = min(len(df_ts), len(df_original))
        df_ts = df_ts.iloc[:min_len].copy()
        df_ts['AsIs_electricity_kWh'] = df_original['Electricity_kWh'].values[:min_len]
    else:
        # ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ baseline mean
        df_ts['AsIs_electricity_kWh'] = baselines.get('asis_elec_kwh', 35) / 96  # per 15-min
    
    if 'CO2_ppm' in df_original.columns:
        min_len = min(len(df_ts), len(df_original))
        df_ts['AsIs_CO2_ppm'] = df_original['CO2_ppm'].values[:min_len]
    else:
        df_ts['AsIs_CO2_ppm'] = 700  # default
    
    # ŸÖÿ≠ÿßÿ≥ÿ®Ÿá Ÿáÿ≤€åŸÜŸá‚ÄåŸáÿß
    df_ts['AsIs_electricity_cost_EUR'] = df_ts['AsIs_electricity_kWh'] * 0.12
    df_ts['RL_electricity_cost_EUR'] = df_ts['RL_electricity_kWh'] * 0.12
    df_ts['AsIs_heating_cost_EUR'] = df_ts.get('AsIs_heating_kWh', df_ts['AsIs_electricity_kWh'] * 0.3) * 0.08
    df_ts['RL_heating_cost_EUR'] = df_ts['RL_heating_kWh'] * 0.08
    df_ts['AsIs_total_cost_EUR'] = df_ts['AsIs_electricity_cost_EUR'] + df_ts['AsIs_heating_cost_EUR']
    df_ts['RL_total_cost_EUR'] = df_ts['RL_electricity_cost_EUR'] + df_ts['RL_heating_cost_EUR']
    
    # ===== ÿ™ÿ¨ŸÖ€åÿπ ÿ±Ÿàÿ≤ÿßŸÜŸá =====
    if 'datetime' in df_ts.columns and df_ts['datetime'].dtype != 'int64':
        df_ts['date'] = pd.to_datetime(df_ts['datetime']).dt.date
    else:
        # ÿ≥ÿßÿÆÿ™ date ÿßÿ≤ step
        df_ts['date'] = pd.date_range('2024-01-01', periods=len(df_ts), freq='15min').date
    
    daily_agg = df_ts.groupby('date').agg({
        'AsIs_electricity_kWh': 'sum',
        'RL_electricity_kWh': 'sum',
        'AsIs_CO2_ppm': 'mean',
        'RL_CO2_ppm': 'mean',
        'AsIs_electricity_cost_EUR': 'sum',
        'RL_electricity_cost_EUR': 'sum',
        'AsIs_heating_cost_EUR': 'sum',
        'RL_heating_cost_EUR': 'sum',
        'AsIs_total_cost_EUR': 'sum',
        'RL_total_cost_EUR': 'sum',
        'occupancy': 'max'  # ÿ≠ÿØÿß⁄©ÿ´ÿ± ÿßÿ¥ÿ∫ÿßŸÑ ÿØÿ± ÿ±Ÿàÿ≤
    }).reset_index()
    
    daily_agg['is_occupied_day'] = daily_agg['occupancy'] > 0
    
    print(f"   ‚úì Timeseries: {len(df_ts)} rows")
    print(f"   ‚úì Daily: {len(daily_agg)} days")
    
    return df_ts, daily_agg


def calculate_cost_dataframes(df_ts: pd.DataFrame, df_daily: pd.DataFrame, 
                              tou_pricing) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """ŸÖÿ≠ÿßÿ≥ÿ®Ÿá DataFrame Ÿáÿß€å Ÿáÿ≤€åŸÜŸá ÿ¨ÿØÿß⁄ØÿßŸÜŸá"""
    
    # Ÿáÿ≤€åŸÜŸá timeseries (ÿß⁄Øÿ± ŸÇÿ®ŸÑÿßŸã ŸÜ€åÿ≥ÿ™)
    costs_ts = df_ts[['datetime', 'AsIs_electricity_cost_EUR', 'RL_electricity_cost_EUR',
                      'AsIs_heating_cost_EUR', 'RL_heating_cost_EUR',
                      'AsIs_total_cost_EUR', 'RL_total_cost_EUR']].copy()
    
    # Ÿáÿ≤€åŸÜŸá daily
    costs_daily = df_daily[['date', 'AsIs_electricity_cost_EUR', 'RL_electricity_cost_EUR',
                            'AsIs_heating_cost_EUR', 'RL_heating_cost_EUR',
                            'AsIs_total_cost_EUR', 'RL_total_cost_EUR']].copy()
    
    # ÿßÿ∂ÿßŸÅŸá ⁄©ÿ±ÿØŸÜ ÿµÿ±ŸÅŸá‚Äåÿ¨Ÿà€å€å
    costs_daily['electricity_savings_EUR'] = costs_daily['AsIs_electricity_cost_EUR'] - costs_daily['RL_electricity_cost_EUR']
    costs_daily['total_savings_EUR'] = costs_daily['AsIs_total_cost_EUR'] - costs_daily['RL_total_cost_EUR']
    costs_daily['electricity_savings_pct'] = costs_daily['electricity_savings_EUR'] / costs_daily['AsIs_electricity_cost_EUR'] * 100
    costs_daily['total_savings_pct'] = costs_daily['total_savings_EUR'] / costs_daily['AsIs_total_cost_EUR'] * 100
    
    return costs_ts, costs_daily


def plot_sweep_comparison(results_df: pd.DataFrame, output_dir: Path):
    """ŸÜŸÖŸàÿØÿßÿ± ŸÖŸÇÿß€åÿ≥Ÿá‚Äåÿß€å ŸáŸÖŸá ÿ≥ŸÜÿßÿ±€åŸàŸáÿß"""
    
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    
    x = results_df['co2_target'].values
    
    # 1. Energy vs CO2 Target
    ax1 = axes[0, 0]
    ax1.plot(x, results_df['asis_energy_kwh'], 'r--o', linewidth=2, markersize=8, label='As-Is')
    ax1.plot(x, results_df['rl_energy_kwh'], 'g-s', linewidth=2, markersize=8, label='RL')
    ax1.fill_between(x, results_df['rl_energy_kwh'], results_df['asis_energy_kwh'], 
                     alpha=0.3, color='green')
    ax1.set_xlabel('CO2 Target (ppm)')
    ax1.set_ylabel('Daily Energy (kWh)')
    ax1.set_title('Energy vs CO2 Target')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    ax1.set_ylim(0, 8)  # ‚úÖ ŸÖÿ≠ÿØŸàÿØŸá ŸÖŸÜÿßÿ≥ÿ®
    
    # 2. Savings % vs CO2 Target
    ax2 = axes[0, 1]
    bars = ax2.bar(x, results_df['savings_pct'], color='#27ae60', edgecolor='black', width=8)
    for bar, val in zip(bars, results_df['savings_pct']):
        ax2.annotate(f'{val:.1f}%', xy=(bar.get_x() + bar.get_width()/2, bar.get_height()),
                     xytext=(0, 3), textcoords='offset points', ha='center', fontsize=10)
    ax2.set_xlabel('CO2 Target (ppm)')
    ax2.set_ylabel('Savings (%)')
    ax2.set_title('Energy Savings vs CO2 Target')
    ax2.grid(True, alpha=0.3)
    ax2.set_ylim(0, 70)  # ‚úÖ ŸÖÿ≠ÿØŸàÿØŸá ŸÖŸÜÿßÿ≥ÿ®
    
    # 3. CO2 Achieved vs Target
    ax3 = axes[0, 2]
    ax3.plot(x, x, 'k--', linewidth=2, label='Target (ideal)')
    ax3.plot(x, results_df['co2_avg'], 'b-o', linewidth=2, markersize=8, label='Achieved Avg')
    ax3.fill_between(x, results_df['co2_avg'], x, alpha=0.3)
    ax3.set_xlabel('CO2 Target (ppm)')
    ax3.set_ylabel('CO2 Achieved (ppm)')
    ax3.set_title('CO2 Target vs Achieved')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    ax3.set_ylim(400, 1100)  # ‚úÖ ŸÖÿ≠ÿØŸàÿØŸá ŸÖŸÜÿßÿ≥ÿ®
    
    # 4. CO2 Max
    ax4 = axes[1, 0]
    ax4.bar(x, results_df['co2_max'], color='#e74c3c', edgecolor='black', width=8)
    ax4.axhline(y=1000, color='red', linestyle='--', linewidth=2, label='Limit (1000 ppm)')
    ax4.set_xlabel('CO2 Target (ppm)')
    ax4.set_ylabel('CO2 Max (ppm)')
    ax4.set_title('Peak CO2 vs Target')
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    ax4.set_ylim(0, 1100)  # ‚úÖ ŸÖÿ≠ÿØŸàÿØŸá ŸÖŸÜÿßÿ≥ÿ®
    
    # 5. Ventilation Factor
    ax5 = axes[1, 1]
    ax5.plot(x, results_df['vent_factor'], 'purple', marker='D', linewidth=2, markersize=8)
    ax5.axhline(y=1.0, color='gray', linestyle='--', label='Baseline (1.0)')
    ax5.set_xlabel('CO2 Target (ppm)')
    ax5.set_ylabel('Ventilation Factor')
    ax5.set_title('Ventilation Factor vs CO2 Target')
    ax5.legend()
    ax5.grid(True, alpha=0.3)
    ax5.set_ylim(0, 1.2)  # ‚úÖ ŸÖÿ≠ÿØŸàÿØŸá ŸÖŸÜÿßÿ≥ÿ®
    
    # 6. Pareto Front (Energy vs CO2)
    ax6 = axes[1, 2]
    scatter = ax6.scatter(results_df['rl_energy_kwh'], results_df['co2_avg'], 
                          c=results_df['co2_target'], cmap='viridis', s=200, edgecolor='black')
    ax6.plot(results_df['rl_energy_kwh'], results_df['co2_avg'], 'k--', alpha=0.5)
    
    for i, row in results_df.iterrows():
        ax6.annotate(f'{int(row["co2_target"])}', 
                     (row['rl_energy_kwh'], row['co2_avg']),
                     xytext=(5, 5), textcoords='offset points', fontsize=9)
    
    plt.colorbar(scatter, ax=ax6, label='CO2 Target (ppm)')
    ax6.set_xlabel('Energy (kWh/day)')
    ax6.set_ylabel('CO2 Achieved (ppm)')
    ax6.set_title('Pareto Front: Energy vs CO2')
    ax6.grid(True, alpha=0.3)
    ax6.set_xlim(2, 6)  # ‚úÖ ŸÖÿ≠ÿØŸàÿØŸá ŸÖŸÜÿßÿ≥ÿ®
    ax6.set_ylim(400, 1100)  # ‚úÖ ŸÖÿ≠ÿØŸàÿØŸá ŸÖŸÜÿßÿ≥ÿ®
    
    plt.suptitle('CO2 Scenario Sweep - Comprehensive Analysis', fontsize=16, fontweight='bold')
    plt.tight_layout()
    
    filepath = output_dir / 'sweep_analysis.png'
    plt.savefig(filepath, dpi=150, bbox_inches='tight', facecolor='white')
    plt.close()
    
    print(f"\nüìä Sweep comparison chart saved: {filepath}")

# =============================================================================
# ÿ™ÿ∫€å€åÿ± ÿØÿ± ÿ®ÿÆÿ¥ SECTION 9 (ÿ™Ÿàÿßÿ®ÿπ ⁄©ŸÖ⁄©€å)
# =============================================================================

def load_data(csv_path: Path, qproxy_path: Optional[Path] = None) -> pd.DataFrame:
    print(f"üìÇ Loading Baseline CSV: {csv_path}")
    df = pd.read_csv(csv_path)
    
    # ÿ™ŸÜÿ∏€åŸÖ ÿß€åŸÜÿØ⁄©ÿ≥ ÿ≤ŸÖÿßŸÜ€å ÿ®ÿ±ÿß€å ŸÅÿß€åŸÑ ÿßÿµŸÑ€å
    for col in ['datetime', 'DateTime']:
        if col in df.columns:
            df[col] = pd.to_datetime(df[col])
            df = df.set_index(col)
            break
            
    # --- ÿßÿ∂ÿßŸÅŸá ⁄©ÿ±ÿØŸÜ ŸÖŸÜÿ∑ŸÇ ÿÆŸàÿßŸÜÿØŸÜ Q-Proxy ---
    if qproxy_path and os.path.exists(qproxy_path):
        print(f"üìÇ Loading Q-Proxy Excel: {qproxy_path}")
        try:
            qx = pd.read_excel(qproxy_path)
            if 'datetime' in qx.columns:
                qx['datetime'] = pd.to_datetime(qx['datetime'])
                qx = qx.set_index('datetime').sort_index()
                
                # Ÿæ€åÿØÿß ⁄©ÿ±ÿØŸÜ ÿ≥ÿ™ŸàŸÜ ÿØÿ®€å ŸáŸàÿß
                q_col = None
                for c in ['q_supply_room_m3s_est', 'q_supply_room_m3s', 'q_room_m3s']:
                    if c in qx.columns:
                        q_col = c
                        break
                
                if q_col:
                    # ÿ±€åÿ≥ŸÖŸæ (Resample) ⁄©ÿ±ÿØŸÜ ÿ®Ÿá €±€µ ÿØŸÇ€åŸÇŸá ÿ®ÿ±ÿß€å ŸáŸÖÿßŸáŸÜ⁄Ø€å ÿ®ÿß ŸÅÿß€åŸÑ ÿßÿµŸÑ€å
                    q_series = pd.to_numeric(qx[q_col], errors='coerce')
                    q_series = q_series.resample('15min').mean()
                    
                    # ÿßÿØÿ∫ÿßŸÖ ÿ®ÿß ÿØ€åÿ™ÿß€å ÿßÿµŸÑ€å
                    # ŸÖÿß ŸÅŸÇÿ∑ ÿ®ÿßÿ≤Ÿá ÿ≤ŸÖÿßŸÜ€å ŸÖÿ¥ÿ™ÿ±⁄© ÿ±ÿß ŸÜ⁄ØŸá ŸÖ€å‚ÄåÿØÿßÿ±€åŸÖ €åÿß Ÿæÿ± ŸÖ€å‚Äå⁄©ŸÜ€åŸÖ
                    df['Q_room_m3s'] = q_series.reindex(df.index).interpolate(method='time').ffill().bfill()
                    print(f"‚úÖ Q-Proxy merged successfully. Mean Q: {df['Q_room_m3s'].mean():.2f}")
                else:
                    print("‚ö†Ô∏è Column 'q_supply_room_m3s_est' not found in Q-proxy file.")
            else:
                print("‚ö†Ô∏è 'datetime' column not found in Q-proxy file.")
        except Exception as e:
            print(f"‚ùå Error loading Q-proxy: {e}")
    else:
        print("‚ö†Ô∏è No Q-proxy file provided or file not found. Using constant baseline.")
        # ÿß⁄Øÿ± ŸÅÿß€åŸÑ ŸÜÿ®ŸàÿØÿå ÿ≥ÿ™ŸàŸÜ ÿÆÿßŸÑ€å ŸÜŸÖÿßŸÜÿØ
        df['Q_room_m3s'] = np.nan

    print(f"‚úÖ Final Data Loaded: {len(df)} rows")
    return df

# =============================================================================
# ‚úÖ ÿ™ÿßÿ®ÿπ main ÿßÿµŸÑÿßÿ≠ ÿ¥ÿØŸá - ÿ¨ÿß€å⁄Øÿ≤€åŸÜ ⁄©ŸÜ ÿØÿ± hvac_rl_optimizer.py
# =============================================================================

def main():
    parser = argparse.ArgumentParser()

    # ===== ŸÖÿ≥€åÿ±Ÿáÿß€å Ÿæÿ±Ÿà⁄òŸá ÿ®ÿ± ÿßÿ≥ÿßÿ≥ ŸÅŸàŸÑÿØÿ± ÿ®ŸÜÿØ€å ÿ¥ŸÖÿß =====
    # __file__ = TEST1/RL/hvac_rl_optimizer_2.py
    # parent.parent = TEST1
    PROJECT_ROOT = Path(__file__).resolve().parent.parent

    DEFAULT_CSV = str((PROJECT_ROOT / "energy" / "Final_Excel4.csv").resolve())
    DEFAULT_QPROXY = str((PROJECT_ROOT / "energy" / "G32TK15_Class2091_Qproxy_full_article_window.xlsx").resolve())
    DEFAULT_OUTPUT = str((PROJECT_ROOT / "Results RL").resolve())

    parser.add_argument('--csv_path', type=str, default=DEFAULT_CSV)
    parser.add_argument('--output_dir', type=str, default=DEFAULT_OUTPUT)
    parser.add_argument('--qproxy_path', type=str, default=DEFAULT_QPROXY, help='Path to the Q-proxy Excel file')
    parser.add_argument('--episodes', type=int, default=300)
    parser.add_argument('--eval_episodes', type=int, default=5)
    parser.add_argument('--target_energy', type=float, default=None)
    parser.add_argument('--co2_target', type=float, default=None)
    parser.add_argument('--load_agent', type=str, default=None)
    parser.add_argument('--eval_only', action='store_true')

    # Sweep args
    parser.add_argument('--sweep', action='store_true', help='Run CO2 sweep across multiple targets')
    parser.add_argument('--sweep_targets', nargs='+', type=int,
                        default=[900, 910, 920, 930, 940, 950, 960, 970, 980, 990, 1000],
                        help='CO2 targets for sweep')
    parser.add_argument('--sweep_charts', action='store_true', help='Generate all charts for each scenario')

    args = parser.parse_args()

    # ===== Ÿáÿ±⁄Ü€å ⁄©ÿßÿ±ÿ®ÿ± ÿ®ÿØŸáÿå ÿÆÿ±Ÿàÿ¨€å ÿ±ÿß ŸÖÿ¨ÿ®Ÿàÿ± ⁄©ŸÜ ÿ®Ÿá Results RL =====
    RESULTS_RL_DIR = PROJECT_ROOT / "Results RL"
    RESULTS_RL_DIR.mkdir(parents=True, exist_ok=True)

    # =========================================================================
    # SWEEP MODE
    # =========================================================================
    if args.sweep:
        print("\n" + "=" * 80)
        print("üîÑ SWEEP MODE ACTIVATED")
        print("=" * 80)

        if args.sweep_charts:
            run_co2_sweep_with_charts(
                csv_path=args.csv_path,
                base_output_dir=str(RESULTS_RL_DIR.resolve()),
                co2_targets=args.sweep_targets,
                episodes=args.episodes
            )
        return

    # =========================================================================
    # SINGLE RUN MODE
    # =========================================================================
    output_dir = RESULTS_RL_DIR
    output_dir.mkdir(parents=True, exist_ok=True)

    # Load data
    df = load_data(Path(args.csv_path), qproxy_path=Path(args.qproxy_path))
    # Initialize configs
    system_config = SystemConfig()
    tou_pricing = TOUPricing()

    # ÿßÿ≥ÿ™ÿÆÿ±ÿßÿ¨ baseline ÿßÿ≤ ÿØ€åÿ™ÿßÿ≥ÿ™
    baselines = compute_dataset_baselines(df, tou_pricing)

    # ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ targets ÿØ€åÿ™ÿßÿ≥ÿ™ ÿß⁄Øÿ± ŸÖÿ¥ÿÆÿµ ŸÜÿ¥ÿØŸá
    target_energy = args.target_energy if args.target_energy else baselines['target_energy_kwh']
    co2_target = args.co2_target if args.co2_target else 970.0

    # ÿ™ŸÜÿ∏€åŸÖ soft/hard limit ÿ®ÿ± ÿßÿ≥ÿßÿ≥ target
    co2_soft_limit = min(co2_target + 30, 990)
    co2_hard_limit = 1000.0

    rl_config = RLConfig(
        num_episodes=args.episodes,
        eval_episodes=args.eval_episodes,
        target_energy_kwh=target_energy,
        co2_target=co2_target,
        co2_soft_limit=co2_soft_limit,
        co2_hard_limit=co2_hard_limit
    )

    print(f"\n" + "=" * 60)
    print("üéØ Final Configuration")
    print("=" * 60)
    print(f"   Target Energy: {rl_config.target_energy_kwh:.2f} kWh/day")
    print(f"   CO2 Target:    {rl_config.co2_target:.0f} ppm")
    print(f"   CO2 Soft:      {rl_config.co2_soft_limit:.0f} ppm")
    print(f"   CO2 Hard:      {rl_config.co2_hard_limit:.0f} ppm")
    print(f"   CO2 Floor:     {system_config.CO2_MIN_PPM:.0f} ppm (physics)")

    # Create environment
    env = HVACEnvironment(df=df, config=system_config,
                         rl_config=rl_config, tou_pricing=tou_pricing)

    # Create agent
    agent = SACAgent(state_dim=env.state_dim, action_dim=env.action_dim, config=rl_config)

    # Load agent ÿß⁄Øÿ± ŸÖÿ¥ÿÆÿµ ÿ¥ÿØŸá
    if args.load_agent:
        agent.load(Path(args.load_agent))
        print(f"‚úÖ Agent loaded from: {args.load_agent}")

    # =========================================================================
    # EVAL ONLY
    # =========================================================================
    if args.eval_only:
        if not args.load_agent:
            print("‚ùå --eval_only requires --load_agent")
            return

        rl_metrics, _ = evaluate_agent(env, agent, rl_config, output_dir,
                                       num_episodes=args.eval_episodes)

        comparison = compare_rl_vs_baseline(rl_metrics, baselines, output_dir,
                                            co2_target=co2_target)

    # =========================================================================
    # TRAIN + EVAL
    # =========================================================================
    else:
        trainer = RLTrainer(env, agent, rl_config, output_dir)
        trainer.train()

        rl_metrics, _ = evaluate_agent(env, agent, rl_config, output_dir,
                                       num_episodes=args.eval_episodes)

        comparison = compare_rl_vs_baseline(rl_metrics, baselines, output_dir,
                                            co2_target=co2_target)

    # =========================================================================
    # Save baselines
    # =========================================================================
    with open(output_dir / 'baselines.json', 'w') as f:
        json.dump({k: float(v) if isinstance(v, (int, float, np.floating)) else v
                  for k, v in baselines.items()}, f, indent=2)

    print(f"\n‚úÖ All results saved to {output_dir}")


if __name__ == "__main__":
    main()